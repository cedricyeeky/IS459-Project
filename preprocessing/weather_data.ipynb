{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5f3da3",
   "metadata": {},
   "source": [
    "# Weather Data (scraping from Weather Underground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9e157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "# Allow nested event loops (needed for Jupyter notebooks)\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9a53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install aiohttp asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f536d4",
   "metadata": {},
   "source": [
    "Frrom `eda.ipynb`, we have found that the top 20 most popular airports by flight traffic in the United States are:\n",
    "\n",
    "ORD, ATL, DFW, LAX, PHX, DEN, DTW, IAH, MSP, SFO, STL, EWR, LAS, CLT, LGA, BOS, PHL, PIT, SLC, SEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953b792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iata_codes_top_20 = ['ORD', 'ATL', 'DFW', 'LAX', 'PHX', 'DEN', 'DTW', 'IAH', 'MSP', 'SFO', 'STL', 'EWR', 'LAS', 'CLT', 'LGA', 'BOS', 'PHL', 'PIT', 'SLC', 'SEA']\n",
    "\n",
    "# Convert to ICAO codes for US airports\n",
    "icao_codes_top_20 = ['K' + code.upper() for code in iata_codes_top_20]\n",
    "\n",
    "# Split into 5 groups for scraping\n",
    "list1, list2, list3, list4, list5 = [icao_codes_top_20[i:i+4] for i in range(0, 20, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479c0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_wunderground_async(session, station, date, semaphore, progress_counter):\n",
    "    \"\"\"Async version of scrape with rate limiting via semaphore\"\"\"\n",
    "    async with semaphore:  # Limit concurrent requests\n",
    "        url = f\"https://api.weather.com/v1/location/{station}:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate={date.replace('-','')}\"\n",
    "        try:\n",
    "            async with session.get(url) as response:\n",
    "                data = await response.json()\n",
    "                if \"observations\" in data and data[\"observations\"]:\n",
    "                    df = pd.DataFrame(data[\"observations\"])\n",
    "                    df = df[[\"obs_id\",\"valid_time_gmt\", \"wx_phrase\",\"temp\", \"precip_hrly\", \"snow_hrly\", \"wspd\", \"clds\", \"rh\",\"vis\"]]\n",
    "                    \n",
    "                    # Update progress counter\n",
    "                    progress_counter['completed'] += 1\n",
    "                    progress_counter['rows'] += len(df)\n",
    "                    \n",
    "                    # Print progress every 100 days\n",
    "                    if progress_counter['completed'] % 100 == 0:\n",
    "                        print(f\"Progress: {progress_counter['completed']}/{progress_counter['total']} days | {progress_counter['rows']:,} rows scraped\")\n",
    "                    \n",
    "                    return df\n",
    "                return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            # Only print SSL errors once per station to avoid spam\n",
    "            if \"SSL\" not in str(e) or date.endswith(\"10-01\"):\n",
    "                print(f\"Error scraping {station} on {date}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "async def scrape_multidate_async(station, start_date, end_date, max_concurrent=20):\n",
    "    \"\"\"Scrape multiple dates for a single station asynchronously\"\"\"\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "    delta = end_date - start_date\n",
    "    \n",
    "    # Create list of dates to scrape\n",
    "    dates = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') \n",
    "             for i in range(delta.days + 1)]\n",
    "    \n",
    "    total_days = len(dates)\n",
    "    \n",
    "    # Progress counter dictionary (mutable so it can be shared across async tasks)\n",
    "    progress_counter = {'completed': 0, 'total': total_days, 'rows': 0}\n",
    "    \n",
    "    # Semaphore to limit concurrent requests (avoid overwhelming the API)\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    # Create SSL context with certifi certificates\n",
    "    ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "    \n",
    "    # Create aiohttp session with timeout and SSL context\n",
    "    timeout = aiohttp.ClientTimeout(total=30)\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context)\n",
    "    \n",
    "    print(f\"Starting to scrape {total_days} days for {station}...\")\n",
    "    \n",
    "    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:\n",
    "        # Create all tasks\n",
    "        tasks = [scrape_wunderground_async(session, station, date, semaphore, progress_counter) \n",
    "                 for date in dates]\n",
    "        \n",
    "        # Execute all tasks concurrently\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    # Filter out empty DataFrames and exceptions\n",
    "    df_list = [df for df in results if isinstance(df, pd.DataFrame) and not df.empty]\n",
    "    \n",
    "    if df_list:\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        print(f\"✓ Scraped {len(df_list)}/{total_days} days for {station} | Total rows: {len(combined_df):,}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"✗ No data scraped for {station}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "async def scrape_all_stations_async(station_list, start_date, end_date):\n",
    "    \"\"\"Scrape all stations asynchronously, one station at a time to avoid conflicts\"\"\"\n",
    "    all_weather = []\n",
    "    total_rows = 0\n",
    "    \n",
    "    for idx, station in enumerate(station_list, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Station {idx}/{len(station_list)}: {station}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        df_weather = await scrape_multidate_async(station, start_date, end_date, max_concurrent=20)\n",
    "        \n",
    "        if not df_weather.empty:\n",
    "            all_weather.append(df_weather)\n",
    "            total_rows += len(df_weather)\n",
    "            print(f\"Running total: {total_rows:,} rows across {len(all_weather)} stations\")\n",
    "        \n",
    "        # Small delay between stations to be respectful to the API\n",
    "        await asyncio.sleep(1)\n",
    "    \n",
    "    return all_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b7321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async scraping for list 1...\n",
      "Stations to scrape: ['KORD', 'KATL', 'KDFW', 'KLAX']\n",
      "\n",
      "============================================================\n",
      "Station 1/4: KORD\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KORD...\n",
      "Progress: 100/7518 days | 2,707 rows scraped\n",
      "Progress: 200/7518 days | 5,460 rows scraped\n",
      "Progress: 300/7518 days | 7,967 rows scraped\n",
      "Progress: 400/7518 days | 10,583 rows scraped\n",
      "Progress: 500/7518 days | 13,359 rows scraped\n",
      "Progress: 600/7518 days | 16,072 rows scraped\n",
      "Progress: 700/7518 days | 18,729 rows scraped\n",
      "Progress: 800/7518 days | 21,317 rows scraped\n",
      "Progress: 900/7518 days | 24,124 rows scraped\n",
      "Progress: 1000/7518 days | 26,843 rows scraped\n",
      "Progress: 1100/7518 days | 29,604 rows scraped\n",
      "Progress: 1200/7518 days | 32,427 rows scraped\n",
      "Progress: 1300/7518 days | 35,255 rows scraped\n",
      "Progress: 1400/7518 days | 37,857 rows scraped\n",
      "Progress: 1500/7518 days | 40,577 rows scraped\n",
      "Progress: 1600/7518 days | 43,497 rows scraped\n",
      "Progress: 1700/7518 days | 46,313 rows scraped\n",
      "Progress: 1800/7518 days | 49,056 rows scraped\n",
      "Progress: 1900/7518 days | 51,942 rows scraped\n",
      "Progress: 2000/7518 days | 55,000 rows scraped\n",
      "Progress: 2100/7518 days | 57,822 rows scraped\n",
      "Progress: 2200/7518 days | 60,558 rows scraped\n",
      "Progress: 2300/7518 days | 63,403 rows scraped\n",
      "Progress: 2400/7518 days | 66,218 rows scraped\n",
      "Progress: 2500/7518 days | 68,836 rows scraped\n",
      "Progress: 2600/7518 days | 71,528 rows scraped\n",
      "Progress: 2700/7518 days | 74,298 rows scraped\n",
      "Progress: 2800/7518 days | 77,023 rows scraped\n",
      "Progress: 2900/7518 days | 79,618 rows scraped\n",
      "Progress: 3000/7518 days | 82,339 rows scraped\n",
      "Progress: 3100/7518 days | 85,229 rows scraped\n",
      "Progress: 3200/7518 days | 87,987 rows scraped\n",
      "Progress: 3300/7518 days | 90,373 rows scraped\n",
      "Progress: 3400/7518 days | 92,759 rows scraped\n",
      "Progress: 3500/7518 days | 95,153 rows scraped\n",
      "Progress: 3600/7518 days | 97,840 rows scraped\n",
      "Progress: 3700/7518 days | 100,570 rows scraped\n",
      "Progress: 3800/7518 days | 103,595 rows scraped\n",
      "Progress: 3900/7518 days | 106,396 rows scraped\n",
      "Progress: 4000/7518 days | 108,998 rows scraped\n",
      "Progress: 4100/7518 days | 111,649 rows scraped\n",
      "Progress: 4200/7518 days | 114,507 rows scraped\n",
      "Progress: 4300/7518 days | 117,171 rows scraped\n",
      "Progress: 4400/7518 days | 119,741 rows scraped\n",
      "Progress: 4500/7518 days | 122,373 rows scraped\n",
      "Progress: 4600/7518 days | 124,998 rows scraped\n",
      "Progress: 4700/7518 days | 127,603 rows scraped\n",
      "Progress: 4800/7518 days | 130,440 rows scraped\n",
      "Progress: 4900/7518 days | 133,386 rows scraped\n",
      "Progress: 5000/7518 days | 136,140 rows scraped\n",
      "Progress: 5100/7518 days | 138,846 rows scraped\n",
      "Progress: 5200/7518 days | 141,607 rows scraped\n",
      "Progress: 5300/7518 days | 144,393 rows scraped\n",
      "Progress: 5400/7518 days | 147,080 rows scraped\n",
      "Progress: 5500/7518 days | 149,791 rows scraped\n",
      "Progress: 5600/7518 days | 152,632 rows scraped\n",
      "Progress: 5700/7518 days | 155,401 rows scraped\n",
      "Progress: 5800/7518 days | 158,106 rows scraped\n",
      "Progress: 5900/7518 days | 160,933 rows scraped\n",
      "Progress: 6000/7518 days | 163,929 rows scraped\n",
      "Progress: 6100/7518 days | 166,611 rows scraped\n",
      "Progress: 6200/7518 days | 169,237 rows scraped\n",
      "Progress: 6300/7518 days | 172,360 rows scraped\n",
      "Progress: 6400/7518 days | 175,136 rows scraped\n",
      "Progress: 6500/7518 days | 177,704 rows scraped\n",
      "Progress: 6600/7518 days | 180,322 rows scraped\n",
      "Progress: 6700/7518 days | 183,243 rows scraped\n",
      "Progress: 6800/7518 days | 185,958 rows scraped\n",
      "Progress: 6900/7518 days | 188,677 rows scraped\n",
      "Progress: 7000/7518 days | 191,510 rows scraped\n",
      "Progress: 7100/7518 days | 194,551 rows scraped\n",
      "Progress: 7200/7518 days | 197,252 rows scraped\n",
      "Progress: 7300/7518 days | 199,975 rows scraped\n",
      "Progress: 7400/7518 days | 203,194 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/z8kvm2x92hn0fh3j63wxtsfw0000gn/T/ipykernel_19370/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7487/7518 days for KORD | Total rows: 205,796\n",
      "Running total: 205,796 rows across 1 stations\n",
      "\n",
      "============================================================\n",
      "Station 2/4: KATL\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KATL...\n",
      "Progress: 100/7518 days | 2,683 rows scraped\n",
      "Progress: 200/7518 days | 5,341 rows scraped\n",
      "Progress: 300/7518 days | 7,923 rows scraped\n",
      "Progress: 400/7518 days | 10,662 rows scraped\n",
      "Progress: 500/7518 days | 13,413 rows scraped\n",
      "Progress: 600/7518 days | 16,156 rows scraped\n",
      "Progress: 700/7518 days | 18,960 rows scraped\n",
      "Progress: 800/7518 days | 21,667 rows scraped\n",
      "Progress: 900/7518 days | 24,414 rows scraped\n",
      "Progress: 1000/7518 days | 27,015 rows scraped\n",
      "Progress: 1100/7518 days | 29,632 rows scraped\n",
      "Progress: 1200/7518 days | 32,369 rows scraped\n",
      "Progress: 1300/7518 days | 35,148 rows scraped\n",
      "Progress: 1400/7518 days | 37,964 rows scraped\n",
      "Progress: 1500/7518 days | 40,602 rows scraped\n",
      "Progress: 1600/7518 days | 43,291 rows scraped\n",
      "Progress: 1700/7518 days | 45,942 rows scraped\n",
      "Progress: 1800/7518 days | 48,725 rows scraped\n",
      "Progress: 1900/7518 days | 51,432 rows scraped\n",
      "Progress: 2000/7518 days | 54,177 rows scraped\n",
      "Progress: 2100/7518 days | 56,758 rows scraped\n",
      "Progress: 2200/7518 days | 59,300 rows scraped\n",
      "Progress: 2300/7518 days | 61,990 rows scraped\n",
      "Progress: 2400/7518 days | 64,607 rows scraped\n",
      "Progress: 2500/7518 days | 67,373 rows scraped\n",
      "Progress: 2600/7518 days | 70,088 rows scraped\n",
      "Progress: 2700/7518 days | 72,913 rows scraped\n",
      "Progress: 2800/7518 days | 75,547 rows scraped\n",
      "Progress: 2900/7518 days | 78,199 rows scraped\n",
      "Progress: 3000/7518 days | 81,238 rows scraped\n",
      "Progress: 3100/7518 days | 84,215 rows scraped\n",
      "Progress: 3200/7518 days | 86,965 rows scraped\n",
      "Progress: 3300/7518 days | 89,352 rows scraped\n",
      "Progress: 3400/7518 days | 91,759 rows scraped\n",
      "Progress: 3500/7518 days | 94,140 rows scraped\n",
      "Progress: 3600/7518 days | 97,025 rows scraped\n",
      "Progress: 3700/7518 days | 99,820 rows scraped\n",
      "Progress: 3800/7518 days | 102,757 rows scraped\n",
      "Progress: 3900/7518 days | 105,645 rows scraped\n",
      "Progress: 4000/7518 days | 108,315 rows scraped\n",
      "Progress: 4100/7518 days | 111,244 rows scraped\n",
      "Progress: 4200/7518 days | 114,135 rows scraped\n",
      "Progress: 4300/7518 days | 116,970 rows scraped\n",
      "Progress: 4400/7518 days | 119,684 rows scraped\n",
      "Progress: 4500/7518 days | 122,427 rows scraped\n",
      "Progress: 4600/7518 days | 125,035 rows scraped\n",
      "Progress: 4700/7518 days | 127,612 rows scraped\n",
      "Progress: 4800/7518 days | 130,339 rows scraped\n",
      "Progress: 4900/7518 days | 133,268 rows scraped\n",
      "Progress: 5000/7518 days | 136,086 rows scraped\n",
      "Progress: 5100/7518 days | 138,886 rows scraped\n",
      "Progress: 5200/7518 days | 141,598 rows scraped\n",
      "Progress: 5300/7518 days | 144,499 rows scraped\n",
      "Progress: 5400/7518 days | 147,253 rows scraped\n",
      "Progress: 5500/7518 days | 150,305 rows scraped\n",
      "Progress: 5600/7518 days | 153,171 rows scraped\n",
      "Progress: 5700/7518 days | 156,208 rows scraped\n",
      "Progress: 5800/7518 days | 159,159 rows scraped\n",
      "Progress: 5900/7518 days | 161,969 rows scraped\n",
      "Progress: 6000/7518 days | 164,710 rows scraped\n",
      "Progress: 6100/7518 days | 167,393 rows scraped\n",
      "Progress: 6200/7518 days | 170,278 rows scraped\n",
      "Progress: 6300/7518 days | 173,178 rows scraped\n",
      "Progress: 6400/7518 days | 176,086 rows scraped\n",
      "Progress: 6500/7518 days | 179,195 rows scraped\n",
      "Progress: 6600/7518 days | 181,951 rows scraped\n",
      "Progress: 6700/7518 days | 184,895 rows scraped\n",
      "Progress: 6800/7518 days | 187,707 rows scraped\n",
      "Progress: 6900/7518 days | 190,573 rows scraped\n",
      "Progress: 7000/7518 days | 193,396 rows scraped\n",
      "Progress: 7100/7518 days | 196,292 rows scraped\n",
      "Progress: 7200/7518 days | 199,002 rows scraped\n",
      "Progress: 7300/7518 days | 201,845 rows scraped\n",
      "Progress: 7400/7518 days | 204,773 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/z8kvm2x92hn0fh3j63wxtsfw0000gn/T/ipykernel_19370/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7486/7518 days for KATL | Total rows: 207,266\n",
      "Running total: 413,062 rows across 2 stations\n",
      "\n",
      "============================================================\n",
      "Station 3/4: KDFW\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KDFW...\n",
      "Progress: 100/7518 days | 2,790 rows scraped\n",
      "Progress: 200/7518 days | 5,549 rows scraped\n",
      "Progress: 300/7518 days | 8,144 rows scraped\n",
      "Progress: 400/7518 days | 10,729 rows scraped\n",
      "Progress: 500/7518 days | 13,573 rows scraped\n",
      "Progress: 600/7518 days | 16,393 rows scraped\n",
      "Progress: 700/7518 days | 19,141 rows scraped\n",
      "Progress: 800/7518 days | 21,724 rows scraped\n",
      "Progress: 900/7518 days | 24,573 rows scraped\n",
      "Progress: 1000/7518 days | 27,468 rows scraped\n",
      "Progress: 1100/7518 days | 30,080 rows scraped\n",
      "Progress: 1200/7518 days | 33,034 rows scraped\n",
      "Progress: 1300/7518 days | 35,970 rows scraped\n",
      "Progress: 1400/7518 days | 38,734 rows scraped\n",
      "Progress: 1500/7518 days | 41,512 rows scraped\n",
      "Progress: 1600/7518 days | 44,593 rows scraped\n",
      "Progress: 1700/7518 days | 47,475 rows scraped\n",
      "Progress: 1800/7518 days | 50,193 rows scraped\n",
      "Progress: 1900/7518 days | 52,927 rows scraped\n",
      "Progress: 2000/7518 days | 55,987 rows scraped\n",
      "Progress: 2100/7518 days | 58,814 rows scraped\n",
      "Progress: 2200/7518 days | 61,370 rows scraped\n",
      "Progress: 2300/7518 days | 64,319 rows scraped\n",
      "Progress: 2400/7518 days | 67,250 rows scraped\n",
      "Progress: 2500/7518 days | 70,072 rows scraped\n",
      "Progress: 2600/7518 days | 72,800 rows scraped\n",
      "Progress: 2700/7518 days | 75,750 rows scraped\n",
      "Progress: 2800/7518 days | 78,748 rows scraped\n",
      "Progress: 2900/7518 days | 81,328 rows scraped\n",
      "Progress: 3000/7518 days | 83,971 rows scraped\n",
      "Progress: 3100/7518 days | 86,691 rows scraped\n",
      "Progress: 3200/7518 days | 89,460 rows scraped\n",
      "Progress: 3300/7518 days | 91,840 rows scraped\n",
      "Progress: 3400/7518 days | 94,232 rows scraped\n",
      "Progress: 3500/7518 days | 96,634 rows scraped\n",
      "Progress: 3600/7518 days | 99,403 rows scraped\n",
      "Progress: 3700/7518 days | 102,200 rows scraped\n",
      "Progress: 3800/7518 days | 105,300 rows scraped\n",
      "Progress: 3900/7518 days | 108,061 rows scraped\n",
      "Progress: 4000/7518 days | 110,647 rows scraped\n",
      "Progress: 4100/7518 days | 113,608 rows scraped\n",
      "Progress: 4200/7518 days | 116,428 rows scraped\n",
      "Progress: 4300/7518 days | 119,243 rows scraped\n",
      "Progress: 4400/7518 days | 121,670 rows scraped\n",
      "Progress: 4500/7518 days | 124,259 rows scraped\n",
      "Progress: 4600/7518 days | 126,951 rows scraped\n",
      "Progress: 4700/7518 days | 129,387 rows scraped\n",
      "Progress: 4800/7518 days | 132,296 rows scraped\n",
      "Progress: 4900/7518 days | 135,296 rows scraped\n",
      "Progress: 5000/7518 days | 137,976 rows scraped\n",
      "Progress: 5100/7518 days | 140,638 rows scraped\n",
      "Progress: 5200/7518 days | 143,392 rows scraped\n",
      "Progress: 5300/7518 days | 146,349 rows scraped\n",
      "Progress: 5400/7518 days | 149,073 rows scraped\n",
      "Progress: 5500/7518 days | 151,869 rows scraped\n",
      "Progress: 5600/7518 days | 154,778 rows scraped\n",
      "Progress: 5700/7518 days | 157,579 rows scraped\n",
      "Progress: 5800/7518 days | 160,172 rows scraped\n",
      "Progress: 5900/7518 days | 162,920 rows scraped\n",
      "Progress: 6000/7518 days | 165,842 rows scraped\n",
      "Progress: 6100/7518 days | 168,644 rows scraped\n",
      "Progress: 6200/7518 days | 171,364 rows scraped\n",
      "Progress: 6300/7518 days | 174,395 rows scraped\n",
      "Progress: 6400/7518 days | 177,118 rows scraped\n",
      "Progress: 6500/7518 days | 179,772 rows scraped\n",
      "Progress: 6600/7518 days | 182,277 rows scraped\n",
      "Progress: 6700/7518 days | 184,937 rows scraped\n",
      "Progress: 6800/7518 days | 187,610 rows scraped\n",
      "Progress: 6900/7518 days | 190,168 rows scraped\n",
      "Progress: 7000/7518 days | 192,914 rows scraped\n",
      "Progress: 7100/7518 days | 195,821 rows scraped\n",
      "Progress: 7200/7518 days | 199,034 rows scraped\n",
      "Progress: 7300/7518 days | 201,762 rows scraped\n",
      "Progress: 7400/7518 days | 204,598 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/z8kvm2x92hn0fh3j63wxtsfw0000gn/T/ipykernel_19370/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7486/7518 days for KDFW | Total rows: 207,091\n",
      "Running total: 620,153 rows across 3 stations\n",
      "\n",
      "============================================================\n",
      "Station 4/4: KLAX\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KLAX...\n",
      "Progress: 100/7518 days | 2,664 rows scraped\n",
      "Progress: 200/7518 days | 5,356 rows scraped\n",
      "Progress: 300/7518 days | 8,072 rows scraped\n",
      "Progress: 400/7518 days | 10,862 rows scraped\n",
      "Progress: 500/7518 days | 13,500 rows scraped\n",
      "Progress: 600/7518 days | 16,193 rows scraped\n",
      "Progress: 700/7518 days | 18,936 rows scraped\n",
      "Progress: 800/7518 days | 21,654 rows scraped\n",
      "Progress: 900/7518 days | 24,319 rows scraped\n",
      "Progress: 1000/7518 days | 27,012 rows scraped\n",
      "Progress: 1100/7518 days | 29,678 rows scraped\n",
      "Progress: 1200/7518 days | 32,308 rows scraped\n",
      "Progress: 1300/7518 days | 35,062 rows scraped\n",
      "Progress: 1400/7518 days | 37,875 rows scraped\n",
      "Progress: 1500/7518 days | 40,979 rows scraped\n",
      "Progress: 1600/7518 days | 43,657 rows scraped\n",
      "Progress: 1700/7518 days | 46,371 rows scraped\n",
      "Progress: 1800/7518 days | 49,198 rows scraped\n",
      "Progress: 1900/7518 days | 51,954 rows scraped\n",
      "Progress: 2000/7518 days | 54,717 rows scraped\n",
      "Progress: 2100/7518 days | 57,472 rows scraped\n",
      "Progress: 2200/7518 days | 60,283 rows scraped\n",
      "Progress: 2300/7518 days | 62,883 rows scraped\n",
      "Progress: 2400/7518 days | 65,620 rows scraped\n",
      "Progress: 2500/7518 days | 68,371 rows scraped\n",
      "Progress: 2600/7518 days | 70,977 rows scraped\n",
      "Progress: 2700/7518 days | 73,774 rows scraped\n",
      "Progress: 2800/7518 days | 76,522 rows scraped\n",
      "Progress: 2900/7518 days | 79,353 rows scraped\n",
      "Progress: 3000/7518 days | 82,190 rows scraped\n",
      "Progress: 3100/7518 days | 84,902 rows scraped\n",
      "Progress: 3200/7518 days | 87,523 rows scraped\n",
      "Progress: 3300/7518 days | 89,915 rows scraped\n",
      "Progress: 3400/7518 days | 92,306 rows scraped\n",
      "Progress: 3500/7518 days | 94,692 rows scraped\n",
      "Progress: 3600/7518 days | 97,278 rows scraped\n",
      "Progress: 3700/7518 days | 99,838 rows scraped\n",
      "Progress: 3800/7518 days | 102,456 rows scraped\n",
      "Progress: 3900/7518 days | 105,086 rows scraped\n",
      "Progress: 4000/7518 days | 107,834 rows scraped\n",
      "Progress: 4100/7518 days | 110,420 rows scraped\n",
      "Progress: 4200/7518 days | 113,022 rows scraped\n",
      "Progress: 4300/7518 days | 115,645 rows scraped\n",
      "Progress: 4400/7518 days | 118,262 rows scraped\n",
      "Progress: 4500/7518 days | 120,884 rows scraped\n",
      "Progress: 4600/7518 days | 123,568 rows scraped\n",
      "Progress: 4700/7518 days | 126,029 rows scraped\n",
      "Progress: 4800/7518 days | 128,845 rows scraped\n",
      "Progress: 4900/7518 days | 131,600 rows scraped\n",
      "Progress: 5000/7518 days | 134,525 rows scraped\n",
      "Progress: 5100/7518 days | 137,328 rows scraped\n",
      "Progress: 5200/7518 days | 140,084 rows scraped\n",
      "Progress: 5300/7518 days | 142,770 rows scraped\n",
      "Progress: 5400/7518 days | 145,537 rows scraped\n",
      "Progress: 5500/7518 days | 148,240 rows scraped\n",
      "Progress: 5600/7518 days | 150,910 rows scraped\n",
      "Progress: 5700/7518 days | 153,689 rows scraped\n",
      "Progress: 5800/7518 days | 156,366 rows scraped\n",
      "Progress: 5900/7518 days | 159,073 rows scraped\n",
      "Progress: 6000/7518 days | 161,781 rows scraped\n",
      "Progress: 6100/7518 days | 164,137 rows scraped\n",
      "Progress: 6200/7518 days | 166,849 rows scraped\n",
      "Progress: 6300/7518 days | 169,538 rows scraped\n",
      "Progress: 6400/7518 days | 172,205 rows scraped\n",
      "Progress: 6500/7518 days | 174,938 rows scraped\n",
      "Progress: 6600/7518 days | 177,629 rows scraped\n",
      "Progress: 6700/7518 days | 180,486 rows scraped\n",
      "Progress: 6800/7518 days | 183,280 rows scraped\n",
      "Progress: 6900/7518 days | 186,065 rows scraped\n",
      "Progress: 7000/7518 days | 188,812 rows scraped\n",
      "Progress: 7100/7518 days | 191,560 rows scraped\n",
      "Progress: 7200/7518 days | 194,331 rows scraped\n",
      "Progress: 7300/7518 days | 196,948 rows scraped\n",
      "Progress: 7400/7518 days | 199,765 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/z8kvm2x92hn0fh3j63wxtsfw0000gn/T/ipykernel_19370/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7485/7518 days for KLAX | Total rows: 202,057\n",
      "Running total: 822,210 rows across 4 stations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/z8kvm2x92hn0fh3j63wxtsfw0000gn/T/ipykernel_19370/635276576.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all_weather_1 = pd.concat(all_weather_1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "✓ Scraping complete!\n",
      "==================================================\n",
      "\n",
      "Total rows scraped: 822,210\n",
      "\n",
      "First 5 rows:\n",
      "  obs_id  valid_time_gmt      wx_phrase  temp  precip_hrly  snow_hrly  wspd  \\\n",
      "0   KORD       560062800           Fair  44.0          NaN        NaN   NaN   \n",
      "1   KORD       560066400           Fair  44.0          NaN        NaN   5.0   \n",
      "2   KORD       560070000           Fair  42.0          NaN        NaN   5.0   \n",
      "3   KORD       560073600  Partly Cloudy  40.0          NaN        NaN   NaN   \n",
      "4   KORD       560077200           Fair  39.0          NaN        NaN   5.0   \n",
      "\n",
      "  clds    rh   vis  \n",
      "0  CLR  79.0  15.0  \n",
      "1  CLR  79.0  15.0  \n",
      "2  CLR  82.0  15.0  \n",
      "3  SCT  89.0  15.0  \n",
      "4  FEW  93.0  15.0  \n",
      "\n",
      "✓ Data saved to: weather_data_list1.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Scrape weather for all ICAO codes (list 1) - OPTIMIZED ASYNC VERSION ---\n",
    "print(\"Starting async scraping for list 1...\")\n",
    "print(f\"Stations to scrape: {list1}\")\n",
    "\n",
    "# Run the async scraping\n",
    "all_weather_1 = await scrape_all_stations_async(list1, '1987-10-01', '2008-04-30')\n",
    "\n",
    "# Combine all stations into one DataFrame\n",
    "if all_weather_1:\n",
    "    df_all_weather_1 = pd.concat(all_weather_1, ignore_index=True)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ Scraping complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nTotal rows scraped: {len(df_all_weather_1):,}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_all_weather_1.head())\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = 'weather_data_list1.csv'\n",
    "    df_all_weather_1.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n✗ No data was scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scrape weather for all ICAO codes (list 2) - OPTIMIZED ASYNC VERSION ---\n",
    "print(\"Starting async scraping for list 2...\")\n",
    "print(f\"Stations to scrape: {list2}\")\n",
    "\n",
    "# Run the async scraping\n",
    "all_weather_2 = await scrape_all_stations_async(list2, '1987-10-01', '2008-04-30')\n",
    "\n",
    "# Combine all stations into one DataFrame\n",
    "if all_weather_2:\n",
    "    df_all_weather_2 = pd.concat(all_weather_2, ignore_index=True)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ Scraping complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nTotal rows scraped: {len(df_all_weather_2):,}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_all_weather_2.head())\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = 'weather_data_list2.csv'\n",
    "    df_all_weather_2.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n✗ No data was scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d7fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async scraping for list 3...\n",
      "Stations to scrape: ['KMSP', 'KSFO', 'KSTL', 'KEWR']\n",
      "\n",
      "============================================================\n",
      "Station 1/4: KMSP\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KMSP...\n",
      "Progress: 100/7518 days | 2,688 rows scraped\n",
      "Progress: 100/7518 days | 2,688 rows scraped\n",
      "Progress: 200/7518 days | 5,381 rows scraped\n",
      "Progress: 200/7518 days | 5,381 rows scraped\n",
      "Progress: 300/7518 days | 7,846 rows scraped\n",
      "Progress: 300/7518 days | 7,846 rows scraped\n",
      "Progress: 400/7518 days | 10,419 rows scraped\n",
      "Progress: 400/7518 days | 10,419 rows scraped\n",
      "Progress: 500/7518 days | 13,111 rows scraped\n",
      "Progress: 500/7518 days | 13,111 rows scraped\n",
      "Progress: 600/7518 days | 15,792 rows scraped\n",
      "Progress: 600/7518 days | 15,792 rows scraped\n",
      "Progress: 700/7518 days | 18,340 rows scraped\n",
      "Progress: 700/7518 days | 18,340 rows scraped\n",
      "Progress: 800/7518 days | 20,889 rows scraped\n",
      "Progress: 800/7518 days | 20,889 rows scraped\n",
      "Progress: 900/7518 days | 23,567 rows scraped\n",
      "Progress: 900/7518 days | 23,567 rows scraped\n",
      "Progress: 1000/7518 days | 26,163 rows scraped\n",
      "Progress: 1000/7518 days | 26,163 rows scraped\n",
      "Progress: 1100/7518 days | 28,772 rows scraped\n",
      "Progress: 1100/7518 days | 28,772 rows scraped\n",
      "Progress: 1200/7518 days | 31,376 rows scraped\n",
      "Progress: 1200/7518 days | 31,376 rows scraped\n",
      "Progress: 1300/7518 days | 34,089 rows scraped\n",
      "Progress: 1300/7518 days | 34,089 rows scraped\n",
      "Progress: 1400/7518 days | 36,727 rows scraped\n",
      "Progress: 1400/7518 days | 36,727 rows scraped\n",
      "Progress: 1500/7518 days | 39,354 rows scraped\n",
      "Progress: 1500/7518 days | 39,354 rows scraped\n",
      "Progress: 1600/7518 days | 42,166 rows scraped\n",
      "Progress: 1600/7518 days | 42,166 rows scraped\n",
      "Progress: 1700/7518 days | 44,841 rows scraped\n",
      "Error scraping KMSP on 1992-07-28: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19920728'\n",
      "Progress: 1700/7518 days | 44,841 rows scraped\n",
      "Error scraping KMSP on 1992-07-28: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19920728'\n",
      "Progress: 1800/7518 days | 47,483 rows scraped\n",
      "Progress: 1800/7518 days | 47,483 rows scraped\n",
      "Progress: 1900/7518 days | 50,152 rows scraped\n",
      "Progress: 1900/7518 days | 50,152 rows scraped\n",
      "Progress: 2000/7518 days | 52,894 rows scraped\n",
      "Progress: 2000/7518 days | 52,894 rows scraped\n",
      "Progress: 2100/7518 days | 55,558 rows scraped\n",
      "Progress: 2100/7518 days | 55,558 rows scraped\n",
      "Progress: 2200/7518 days | 58,175 rows scraped\n",
      "Error scraping KMSP on 1993-11-02: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19931102'\n",
      "Progress: 2200/7518 days | 58,175 rows scraped\n",
      "Error scraping KMSP on 1993-11-02: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19931102'\n",
      "Progress: 2300/7518 days | 60,848 rows scraped\n",
      "Progress: 2300/7518 days | 60,848 rows scraped\n",
      "Progress: 2400/7518 days | 63,484 rows scraped\n",
      "Progress: 2400/7518 days | 63,484 rows scraped\n",
      "Progress: 2500/7518 days | 66,064 rows scraped\n",
      "Progress: 2500/7518 days | 66,064 rows scraped\n",
      "Error scraping KMSP on 1994-10-29: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19941029'\n",
      "Progress: 2600/7518 days | 68,686 rows scraped\n",
      "Error scraping KMSP on 1994-10-29: 400, message='Attempt to decode JSON with unexpected mimetype: text/html', url='https://api.weather.com/v1/location/KMSP:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=19941029'\n",
      "Progress: 2600/7518 days | 68,686 rows scraped\n",
      "Progress: 2700/7518 days | 71,360 rows scraped\n",
      "Progress: 2700/7518 days | 71,360 rows scraped\n",
      "Progress: 2800/7518 days | 74,007 rows scraped\n",
      "Progress: 2800/7518 days | 74,007 rows scraped\n",
      "Progress: 2900/7518 days | 76,604 rows scraped\n",
      "Progress: 2900/7518 days | 76,604 rows scraped\n",
      "Progress: 3000/7518 days | 79,385 rows scraped\n",
      "Progress: 3000/7518 days | 79,385 rows scraped\n",
      "Progress: 3100/7518 days | 82,248 rows scraped\n",
      "Progress: 3100/7518 days | 82,248 rows scraped\n",
      "Progress: 3200/7518 days | 84,991 rows scraped\n",
      "Progress: 3200/7518 days | 84,991 rows scraped\n",
      "Progress: 3300/7518 days | 87,369 rows scraped\n",
      "Progress: 3300/7518 days | 87,369 rows scraped\n",
      "Progress: 3400/7518 days | 89,807 rows scraped\n",
      "Progress: 3400/7518 days | 89,807 rows scraped\n",
      "Progress: 3500/7518 days | 92,220 rows scraped\n",
      "Progress: 3500/7518 days | 92,220 rows scraped\n",
      "Progress: 3600/7518 days | 95,019 rows scraped\n",
      "Progress: 3600/7518 days | 95,019 rows scraped\n",
      "Progress: 3700/7518 days | 97,886 rows scraped\n",
      "Progress: 3700/7518 days | 97,886 rows scraped\n",
      "Progress: 3800/7518 days | 101,280 rows scraped\n",
      "Progress: 3800/7518 days | 101,280 rows scraped\n",
      "Progress: 3900/7518 days | 104,179 rows scraped\n",
      "Progress: 3900/7518 days | 104,179 rows scraped\n",
      "Progress: 4000/7518 days | 106,965 rows scraped\n",
      "Progress: 4000/7518 days | 106,965 rows scraped\n",
      "Progress: 4100/7518 days | 109,845 rows scraped\n",
      "Progress: 4100/7518 days | 109,845 rows scraped\n",
      "Progress: 4200/7518 days | 112,874 rows scraped\n",
      "Progress: 4200/7518 days | 112,874 rows scraped\n",
      "Progress: 4300/7518 days | 115,734 rows scraped\n",
      "Progress: 4300/7518 days | 115,734 rows scraped\n",
      "Progress: 4400/7518 days | 118,388 rows scraped\n",
      "Progress: 4400/7518 days | 118,388 rows scraped\n",
      "Progress: 4500/7518 days | 121,132 rows scraped\n",
      "Progress: 4500/7518 days | 121,132 rows scraped\n",
      "Progress: 4600/7518 days | 123,869 rows scraped\n",
      "Progress: 4600/7518 days | 123,869 rows scraped\n",
      "Progress: 4700/7518 days | 126,510 rows scraped\n",
      "Progress: 4700/7518 days | 126,510 rows scraped\n",
      "Progress: 4800/7518 days | 129,678 rows scraped\n",
      "Progress: 4800/7518 days | 129,678 rows scraped\n",
      "Progress: 4900/7518 days | 132,832 rows scraped\n",
      "Progress: 4900/7518 days | 132,832 rows scraped\n",
      "Progress: 5000/7518 days | 135,748 rows scraped\n",
      "Progress: 5000/7518 days | 135,748 rows scraped\n",
      "Progress: 5100/7518 days | 138,481 rows scraped\n",
      "Progress: 5100/7518 days | 138,481 rows scraped\n",
      "Progress: 5200/7518 days | 141,429 rows scraped\n",
      "Progress: 5200/7518 days | 141,429 rows scraped\n",
      "Progress: 5300/7518 days | 144,467 rows scraped\n",
      "Progress: 5300/7518 days | 144,467 rows scraped\n",
      "Progress: 5400/7518 days | 147,248 rows scraped\n",
      "Progress: 5400/7518 days | 147,248 rows scraped\n",
      "Progress: 5500/7518 days | 150,104 rows scraped\n",
      "Progress: 5500/7518 days | 150,104 rows scraped\n",
      "Progress: 5600/7518 days | 152,923 rows scraped\n",
      "Progress: 5600/7518 days | 152,923 rows scraped\n",
      "Progress: 5700/7518 days | 155,757 rows scraped\n",
      "Progress: 5700/7518 days | 155,757 rows scraped\n",
      "Progress: 5800/7518 days | 158,401 rows scraped\n",
      "Progress: 5800/7518 days | 158,401 rows scraped\n",
      "Progress: 5900/7518 days | 161,293 rows scraped\n",
      "Progress: 5900/7518 days | 161,293 rows scraped\n",
      "Progress: 6000/7518 days | 164,400 rows scraped\n",
      "Progress: 6000/7518 days | 164,400 rows scraped\n",
      "Progress: 6100/7518 days | 167,199 rows scraped\n",
      "Progress: 6100/7518 days | 167,199 rows scraped\n",
      "Progress: 6200/7518 days | 169,948 rows scraped\n",
      "Progress: 6200/7518 days | 169,948 rows scraped\n",
      "Progress: 6300/7518 days | 172,850 rows scraped\n",
      "Progress: 6300/7518 days | 172,850 rows scraped\n",
      "Progress: 6400/7518 days | 175,693 rows scraped\n",
      "Progress: 6400/7518 days | 175,693 rows scraped\n",
      "Progress: 6500/7518 days | 178,394 rows scraped\n",
      "Progress: 6500/7518 days | 178,394 rows scraped\n",
      "Progress: 6600/7518 days | 181,310 rows scraped\n",
      "Progress: 6600/7518 days | 181,310 rows scraped\n",
      "Progress: 6700/7518 days | 184,389 rows scraped\n",
      "Progress: 6700/7518 days | 184,389 rows scraped\n",
      "Progress: 6800/7518 days | 187,106 rows scraped\n",
      "Progress: 6800/7518 days | 187,106 rows scraped\n",
      "Progress: 6900/7518 days | 189,933 rows scraped\n",
      "Progress: 6900/7518 days | 189,933 rows scraped\n",
      "Progress: 7000/7518 days | 192,727 rows scraped\n",
      "Progress: 7000/7518 days | 192,727 rows scraped\n",
      "Progress: 7100/7518 days | 195,827 rows scraped\n",
      "Progress: 7100/7518 days | 195,827 rows scraped\n",
      "Progress: 7200/7518 days | 198,470 rows scraped\n",
      "Progress: 7200/7518 days | 198,470 rows scraped\n",
      "Progress: 7300/7518 days | 201,418 rows scraped\n",
      "Progress: 7300/7518 days | 201,418 rows scraped\n",
      "Progress: 7400/7518 days | 204,577 rows scraped\n",
      "Progress: 7400/7518 days | 204,577 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7484/7518 days for KMSP | Total rows: 207,237\n",
      "Running total: 207,237 rows across 1 stations\n",
      "\n",
      "============================================================\n",
      "Station 2/4: KSFO\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSFO...\n",
      "\n",
      "============================================================\n",
      "Station 2/4: KSFO\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSFO...\n",
      "Progress: 100/7518 days | 2,910 rows scraped\n",
      "Progress: 100/7518 days | 2,910 rows scraped\n",
      "Progress: 200/7518 days | 5,584 rows scraped\n",
      "Progress: 200/7518 days | 5,584 rows scraped\n",
      "Progress: 300/7518 days | 8,267 rows scraped\n",
      "Progress: 300/7518 days | 8,267 rows scraped\n",
      "Progress: 400/7518 days | 11,043 rows scraped\n",
      "Progress: 400/7518 days | 11,043 rows scraped\n",
      "Progress: 500/7518 days | 13,938 rows scraped\n",
      "Progress: 500/7518 days | 13,938 rows scraped\n",
      "Progress: 600/7518 days | 16,834 rows scraped\n",
      "Progress: 600/7518 days | 16,834 rows scraped\n",
      "Progress: 700/7518 days | 19,486 rows scraped\n",
      "Progress: 700/7518 days | 19,486 rows scraped\n",
      "Progress: 800/7518 days | 22,218 rows scraped\n",
      "Progress: 800/7518 days | 22,218 rows scraped\n",
      "Progress: 900/7518 days | 24,955 rows scraped\n",
      "Progress: 900/7518 days | 24,955 rows scraped\n",
      "Progress: 1000/7518 days | 27,659 rows scraped\n",
      "Progress: 1000/7518 days | 27,659 rows scraped\n",
      "Progress: 1100/7518 days | 30,456 rows scraped\n",
      "Progress: 1100/7518 days | 30,456 rows scraped\n",
      "Progress: 1200/7518 days | 33,100 rows scraped\n",
      "Progress: 1200/7518 days | 33,100 rows scraped\n",
      "Progress: 1300/7518 days | 35,922 rows scraped\n",
      "Progress: 1300/7518 days | 35,922 rows scraped\n",
      "Progress: 1400/7518 days | 38,656 rows scraped\n",
      "Progress: 1400/7518 days | 38,656 rows scraped\n",
      "Progress: 1500/7518 days | 41,429 rows scraped\n",
      "Progress: 1500/7518 days | 41,429 rows scraped\n",
      "Progress: 1600/7518 days | 44,036 rows scraped\n",
      "Progress: 1600/7518 days | 44,036 rows scraped\n",
      "Progress: 1700/7518 days | 46,654 rows scraped\n",
      "Progress: 1700/7518 days | 46,654 rows scraped\n",
      "Progress: 1800/7518 days | 49,304 rows scraped\n",
      "Progress: 1800/7518 days | 49,304 rows scraped\n",
      "Progress: 1900/7518 days | 51,980 rows scraped\n",
      "Progress: 1900/7518 days | 51,980 rows scraped\n",
      "Progress: 2000/7518 days | 54,727 rows scraped\n",
      "Progress: 2000/7518 days | 54,727 rows scraped\n",
      "Progress: 2100/7518 days | 57,376 rows scraped\n",
      "Progress: 2100/7518 days | 57,376 rows scraped\n",
      "Progress: 2200/7518 days | 60,056 rows scraped\n",
      "Progress: 2200/7518 days | 60,056 rows scraped\n",
      "Progress: 2300/7518 days | 62,709 rows scraped\n",
      "Progress: 2300/7518 days | 62,709 rows scraped\n",
      "Progress: 2400/7518 days | 65,446 rows scraped\n",
      "Progress: 2400/7518 days | 65,446 rows scraped\n",
      "Progress: 2500/7518 days | 68,181 rows scraped\n",
      "Progress: 2500/7518 days | 68,181 rows scraped\n",
      "Progress: 2600/7518 days | 70,844 rows scraped\n",
      "Progress: 2600/7518 days | 70,844 rows scraped\n",
      "Progress: 2700/7518 days | 73,695 rows scraped\n",
      "Progress: 2700/7518 days | 73,695 rows scraped\n",
      "Progress: 2800/7518 days | 76,556 rows scraped\n",
      "Progress: 2800/7518 days | 76,556 rows scraped\n",
      "Progress: 2900/7518 days | 79,164 rows scraped\n",
      "Progress: 2900/7518 days | 79,164 rows scraped\n",
      "Progress: 3000/7518 days | 81,899 rows scraped\n",
      "Progress: 3000/7518 days | 81,899 rows scraped\n",
      "Progress: 3100/7518 days | 84,629 rows scraped\n",
      "Progress: 3100/7518 days | 84,629 rows scraped\n",
      "Progress: 3200/7518 days | 87,210 rows scraped\n",
      "Progress: 3200/7518 days | 87,210 rows scraped\n",
      "Progress: 3300/7518 days | 89,558 rows scraped\n",
      "Progress: 3300/7518 days | 89,558 rows scraped\n",
      "Progress: 3400/7518 days | 91,940 rows scraped\n",
      "Progress: 3400/7518 days | 91,940 rows scraped\n",
      "Progress: 3500/7518 days | 94,313 rows scraped\n",
      "Progress: 3500/7518 days | 94,313 rows scraped\n",
      "Progress: 3600/7518 days | 96,825 rows scraped\n",
      "Progress: 3600/7518 days | 96,825 rows scraped\n",
      "Progress: 3700/7518 days | 99,387 rows scraped\n",
      "Progress: 3700/7518 days | 99,387 rows scraped\n",
      "Progress: 3800/7518 days | 102,264 rows scraped\n",
      "Progress: 3800/7518 days | 102,264 rows scraped\n",
      "Progress: 3900/7518 days | 104,882 rows scraped\n",
      "Progress: 3900/7518 days | 104,882 rows scraped\n",
      "Progress: 4000/7518 days | 107,440 rows scraped\n",
      "Progress: 4000/7518 days | 107,440 rows scraped\n",
      "Progress: 4100/7518 days | 110,097 rows scraped\n",
      "Progress: 4100/7518 days | 110,097 rows scraped\n",
      "Progress: 4200/7518 days | 112,854 rows scraped\n",
      "Progress: 4200/7518 days | 112,854 rows scraped\n",
      "Progress: 4300/7518 days | 115,418 rows scraped\n",
      "Progress: 4300/7518 days | 115,418 rows scraped\n",
      "Progress: 4400/7518 days | 118,013 rows scraped\n",
      "Progress: 4400/7518 days | 118,013 rows scraped\n",
      "Progress: 4500/7518 days | 120,605 rows scraped\n",
      "Progress: 4500/7518 days | 120,605 rows scraped\n",
      "Progress: 4600/7518 days | 123,204 rows scraped\n",
      "Progress: 4600/7518 days | 123,204 rows scraped\n",
      "Progress: 4700/7518 days | 125,672 rows scraped\n",
      "Progress: 4700/7518 days | 125,672 rows scraped\n",
      "Progress: 4800/7518 days | 128,346 rows scraped\n",
      "Progress: 4800/7518 days | 128,346 rows scraped\n",
      "Progress: 4900/7518 days | 131,006 rows scraped\n",
      "Progress: 4900/7518 days | 131,006 rows scraped\n",
      "Progress: 5000/7518 days | 133,581 rows scraped\n",
      "Progress: 5000/7518 days | 133,581 rows scraped\n",
      "Progress: 5100/7518 days | 136,245 rows scraped\n",
      "Progress: 5100/7518 days | 136,245 rows scraped\n",
      "Progress: 5200/7518 days | 139,013 rows scraped\n",
      "Progress: 5200/7518 days | 139,013 rows scraped\n",
      "Progress: 5300/7518 days | 141,694 rows scraped\n",
      "Progress: 5300/7518 days | 141,694 rows scraped\n",
      "Progress: 5400/7518 days | 144,304 rows scraped\n",
      "Progress: 5400/7518 days | 144,304 rows scraped\n",
      "Progress: 5500/7518 days | 146,896 rows scraped\n",
      "Progress: 5500/7518 days | 146,896 rows scraped\n",
      "Progress: 5600/7518 days | 149,581 rows scraped\n",
      "Progress: 5600/7518 days | 149,581 rows scraped\n",
      "Progress: 5700/7518 days | 152,156 rows scraped\n",
      "Progress: 5700/7518 days | 152,156 rows scraped\n",
      "Progress: 5800/7518 days | 154,744 rows scraped\n",
      "Progress: 5800/7518 days | 154,744 rows scraped\n",
      "Progress: 5900/7518 days | 157,368 rows scraped\n",
      "Progress: 5900/7518 days | 157,368 rows scraped\n",
      "Progress: 6000/7518 days | 160,044 rows scraped\n",
      "Progress: 6000/7518 days | 160,044 rows scraped\n",
      "Progress: 6100/7518 days | 162,495 rows scraped\n",
      "Progress: 6100/7518 days | 162,495 rows scraped\n",
      "Progress: 6200/7518 days | 165,127 rows scraped\n",
      "Progress: 6200/7518 days | 165,127 rows scraped\n",
      "Progress: 6300/7518 days | 167,832 rows scraped\n",
      "Progress: 6300/7518 days | 167,832 rows scraped\n",
      "Progress: 6400/7518 days | 170,406 rows scraped\n",
      "Progress: 6400/7518 days | 170,406 rows scraped\n",
      "Progress: 6500/7518 days | 173,050 rows scraped\n",
      "Progress: 6500/7518 days | 173,050 rows scraped\n",
      "Progress: 6600/7518 days | 175,711 rows scraped\n",
      "Progress: 6600/7518 days | 175,711 rows scraped\n",
      "Progress: 6700/7518 days | 178,476 rows scraped\n",
      "Progress: 6700/7518 days | 178,476 rows scraped\n",
      "Progress: 6800/7518 days | 181,061 rows scraped\n",
      "Progress: 6800/7518 days | 181,061 rows scraped\n",
      "Progress: 6900/7518 days | 183,658 rows scraped\n",
      "Progress: 6900/7518 days | 183,658 rows scraped\n",
      "Progress: 7000/7518 days | 186,332 rows scraped\n",
      "Progress: 7000/7518 days | 186,332 rows scraped\n",
      "Progress: 7100/7518 days | 189,009 rows scraped\n",
      "Progress: 7100/7518 days | 189,009 rows scraped\n",
      "Progress: 7200/7518 days | 191,567 rows scraped\n",
      "Progress: 7200/7518 days | 191,567 rows scraped\n",
      "Progress: 7300/7518 days | 194,128 rows scraped\n",
      "Progress: 7300/7518 days | 194,128 rows scraped\n",
      "Progress: 7400/7518 days | 196,844 rows scraped\n",
      "Progress: 7400/7518 days | 196,844 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7487/7518 days for KSFO | Total rows: 199,134\n",
      "Running total: 406,371 rows across 2 stations\n",
      "\n",
      "============================================================\n",
      "Station 3/4: KSTL\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSTL...\n",
      "\n",
      "============================================================\n",
      "Station 3/4: KSTL\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSTL...\n",
      "Progress: 100/7518 days | 3,072 rows scraped\n",
      "Progress: 100/7518 days | 3,072 rows scraped\n",
      "Progress: 200/7518 days | 6,172 rows scraped\n",
      "Progress: 200/7518 days | 6,172 rows scraped\n",
      "Progress: 300/7518 days | 8,813 rows scraped\n",
      "Progress: 300/7518 days | 8,813 rows scraped\n",
      "Progress: 400/7518 days | 11,505 rows scraped\n",
      "Progress: 400/7518 days | 11,505 rows scraped\n",
      "Progress: 500/7518 days | 14,602 rows scraped\n",
      "Progress: 500/7518 days | 14,602 rows scraped\n",
      "Progress: 600/7518 days | 17,580 rows scraped\n",
      "Progress: 600/7518 days | 17,580 rows scraped\n",
      "Progress: 700/7518 days | 20,484 rows scraped\n",
      "Progress: 700/7518 days | 20,484 rows scraped\n",
      "Progress: 800/7518 days | 23,311 rows scraped\n",
      "Progress: 800/7518 days | 23,311 rows scraped\n",
      "Progress: 900/7518 days | 26,226 rows scraped\n",
      "Progress: 900/7518 days | 26,226 rows scraped\n",
      "Progress: 1000/7518 days | 29,172 rows scraped\n",
      "Progress: 1000/7518 days | 29,172 rows scraped\n",
      "Progress: 1100/7518 days | 31,948 rows scraped\n",
      "Progress: 1100/7518 days | 31,948 rows scraped\n",
      "Progress: 1200/7518 days | 35,088 rows scraped\n",
      "Progress: 1200/7518 days | 35,088 rows scraped\n",
      "Progress: 1300/7518 days | 38,131 rows scraped\n",
      "Progress: 1300/7518 days | 38,131 rows scraped\n",
      "Progress: 1400/7518 days | 40,995 rows scraped\n",
      "Progress: 1400/7518 days | 40,995 rows scraped\n",
      "Progress: 1500/7518 days | 43,782 rows scraped\n",
      "Progress: 1500/7518 days | 43,782 rows scraped\n",
      "Progress: 1600/7518 days | 46,810 rows scraped\n",
      "Progress: 1600/7518 days | 46,810 rows scraped\n",
      "Progress: 1700/7518 days | 49,692 rows scraped\n",
      "Progress: 1700/7518 days | 49,692 rows scraped\n",
      "Progress: 1800/7518 days | 52,464 rows scraped\n",
      "Progress: 1800/7518 days | 52,464 rows scraped\n",
      "Progress: 1900/7518 days | 55,406 rows scraped\n",
      "Progress: 1900/7518 days | 55,406 rows scraped\n",
      "Progress: 2000/7518 days | 58,676 rows scraped\n",
      "Progress: 2000/7518 days | 58,676 rows scraped\n",
      "Progress: 2100/7518 days | 61,719 rows scraped\n",
      "Progress: 2100/7518 days | 61,719 rows scraped\n",
      "Progress: 2200/7518 days | 64,604 rows scraped\n",
      "Progress: 2200/7518 days | 64,604 rows scraped\n",
      "Progress: 2300/7518 days | 67,735 rows scraped\n",
      "Progress: 2300/7518 days | 67,735 rows scraped\n",
      "Progress: 2400/7518 days | 70,756 rows scraped\n",
      "Progress: 2400/7518 days | 70,756 rows scraped\n",
      "Progress: 2500/7518 days | 73,437 rows scraped\n",
      "Progress: 2500/7518 days | 73,437 rows scraped\n",
      "Progress: 2600/7518 days | 76,152 rows scraped\n",
      "Progress: 2600/7518 days | 76,152 rows scraped\n",
      "Progress: 2700/7518 days | 79,281 rows scraped\n",
      "Progress: 2700/7518 days | 79,281 rows scraped\n",
      "Progress: 2800/7518 days | 82,225 rows scraped\n",
      "Progress: 2800/7518 days | 82,225 rows scraped\n",
      "Progress: 2900/7518 days | 84,917 rows scraped\n",
      "Progress: 2900/7518 days | 84,917 rows scraped\n",
      "Progress: 3000/7518 days | 87,616 rows scraped\n",
      "Progress: 3000/7518 days | 87,616 rows scraped\n",
      "Progress: 3100/7518 days | 90,534 rows scraped\n",
      "Progress: 3100/7518 days | 90,534 rows scraped\n",
      "Progress: 3200/7518 days | 93,555 rows scraped\n",
      "Progress: 3200/7518 days | 93,555 rows scraped\n",
      "Progress: 3300/7518 days | 95,986 rows scraped\n",
      "Progress: 3300/7518 days | 95,986 rows scraped\n",
      "Progress: 3400/7518 days | 98,394 rows scraped\n",
      "Progress: 3400/7518 days | 98,394 rows scraped\n",
      "Progress: 3500/7518 days | 100,800 rows scraped\n",
      "Progress: 3500/7518 days | 100,800 rows scraped\n",
      "Progress: 3600/7518 days | 103,626 rows scraped\n",
      "Progress: 3600/7518 days | 103,626 rows scraped\n",
      "Progress: 3700/7518 days | 106,607 rows scraped\n",
      "Progress: 3700/7518 days | 106,607 rows scraped\n",
      "Progress: 3800/7518 days | 110,120 rows scraped\n",
      "Progress: 3800/7518 days | 110,120 rows scraped\n",
      "Progress: 3900/7518 days | 113,340 rows scraped\n",
      "Progress: 3900/7518 days | 113,340 rows scraped\n",
      "Progress: 4000/7518 days | 116,206 rows scraped\n",
      "Progress: 4000/7518 days | 116,206 rows scraped\n",
      "Progress: 4100/7518 days | 119,056 rows scraped\n",
      "Progress: 4100/7518 days | 119,056 rows scraped\n",
      "Progress: 4200/7518 days | 122,110 rows scraped\n",
      "Progress: 4200/7518 days | 122,110 rows scraped\n",
      "Progress: 4300/7518 days | 125,022 rows scraped\n",
      "Progress: 4300/7518 days | 125,022 rows scraped\n",
      "Progress: 4400/7518 days | 127,633 rows scraped\n",
      "Progress: 4400/7518 days | 127,633 rows scraped\n",
      "Progress: 4500/7518 days | 130,362 rows scraped\n",
      "Progress: 4500/7518 days | 130,362 rows scraped\n",
      "Progress: 4600/7518 days | 133,120 rows scraped\n",
      "Progress: 4600/7518 days | 133,120 rows scraped\n",
      "Progress: 4700/7518 days | 135,789 rows scraped\n",
      "Progress: 4700/7518 days | 135,789 rows scraped\n",
      "Progress: 4800/7518 days | 138,779 rows scraped\n",
      "Progress: 4800/7518 days | 138,779 rows scraped\n",
      "Progress: 4900/7518 days | 141,846 rows scraped\n",
      "Progress: 4900/7518 days | 141,846 rows scraped\n",
      "Progress: 5000/7518 days | 144,570 rows scraped\n",
      "Progress: 5000/7518 days | 144,570 rows scraped\n",
      "Progress: 5100/7518 days | 147,342 rows scraped\n",
      "Progress: 5100/7518 days | 147,342 rows scraped\n",
      "Progress: 5200/7518 days | 150,115 rows scraped\n",
      "Progress: 5200/7518 days | 150,115 rows scraped\n",
      "Progress: 5300/7518 days | 153,186 rows scraped\n",
      "Progress: 5300/7518 days | 153,186 rows scraped\n",
      "Progress: 5400/7518 days | 155,996 rows scraped\n",
      "Progress: 5400/7518 days | 155,996 rows scraped\n",
      "Progress: 5500/7518 days | 158,847 rows scraped\n",
      "Progress: 5500/7518 days | 158,847 rows scraped\n",
      "Progress: 5600/7518 days | 161,871 rows scraped\n",
      "Progress: 5600/7518 days | 161,871 rows scraped\n",
      "Progress: 5700/7518 days | 164,850 rows scraped\n",
      "Progress: 5700/7518 days | 164,850 rows scraped\n",
      "Progress: 5800/7518 days | 167,558 rows scraped\n",
      "Progress: 5800/7518 days | 167,558 rows scraped\n",
      "Progress: 5900/7518 days | 170,513 rows scraped\n",
      "Progress: 5900/7518 days | 170,513 rows scraped\n",
      "Progress: 6000/7518 days | 173,400 rows scraped\n",
      "Progress: 6000/7518 days | 173,400 rows scraped\n",
      "Progress: 6100/7518 days | 176,224 rows scraped\n",
      "Progress: 6100/7518 days | 176,224 rows scraped\n",
      "Progress: 6200/7518 days | 179,009 rows scraped\n",
      "Progress: 6200/7518 days | 179,009 rows scraped\n",
      "Progress: 6300/7518 days | 182,312 rows scraped\n",
      "Progress: 6300/7518 days | 182,312 rows scraped\n",
      "Progress: 6400/7518 days | 185,173 rows scraped\n",
      "Progress: 6400/7518 days | 185,173 rows scraped\n",
      "Progress: 6500/7518 days | 187,913 rows scraped\n",
      "Progress: 6500/7518 days | 187,913 rows scraped\n",
      "Progress: 6600/7518 days | 190,684 rows scraped\n",
      "Progress: 6600/7518 days | 190,684 rows scraped\n",
      "Progress: 6700/7518 days | 193,605 rows scraped\n",
      "Progress: 6700/7518 days | 193,605 rows scraped\n",
      "Progress: 6800/7518 days | 196,417 rows scraped\n",
      "Progress: 6800/7518 days | 196,417 rows scraped\n",
      "Progress: 6900/7518 days | 199,104 rows scraped\n",
      "Progress: 6900/7518 days | 199,104 rows scraped\n",
      "Progress: 7000/7518 days | 202,018 rows scraped\n",
      "Progress: 7000/7518 days | 202,018 rows scraped\n",
      "Progress: 7100/7518 days | 205,039 rows scraped\n",
      "Progress: 7100/7518 days | 205,039 rows scraped\n",
      "Progress: 7200/7518 days | 207,815 rows scraped\n",
      "Progress: 7200/7518 days | 207,815 rows scraped\n",
      "Progress: 7300/7518 days | 210,505 rows scraped\n",
      "Progress: 7300/7518 days | 210,505 rows scraped\n",
      "Progress: 7400/7518 days | 213,637 rows scraped\n",
      "Progress: 7400/7518 days | 213,637 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7487/7518 days for KSTL | Total rows: 216,551\n",
      "Running total: 622,922 rows across 3 stations\n",
      "\n",
      "============================================================\n",
      "Station 4/4: KEWR\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KEWR...\n",
      "\n",
      "============================================================\n",
      "Station 4/4: KEWR\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KEWR...\n",
      "Progress: 100/7518 days | 2,619 rows scraped\n",
      "Progress: 100/7518 days | 2,619 rows scraped\n",
      "Progress: 200/7518 days | 5,212 rows scraped\n",
      "Progress: 200/7518 days | 5,212 rows scraped\n",
      "Progress: 300/7518 days | 7,867 rows scraped\n",
      "Progress: 300/7518 days | 7,867 rows scraped\n",
      "Progress: 400/7518 days | 10,392 rows scraped\n",
      "Progress: 400/7518 days | 10,392 rows scraped\n",
      "Progress: 500/7518 days | 12,957 rows scraped\n",
      "Progress: 500/7518 days | 12,957 rows scraped\n",
      "Progress: 600/7518 days | 15,535 rows scraped\n",
      "Progress: 600/7518 days | 15,535 rows scraped\n",
      "Progress: 700/7518 days | 18,173 rows scraped\n",
      "Progress: 700/7518 days | 18,173 rows scraped\n",
      "Progress: 800/7518 days | 20,763 rows scraped\n",
      "Progress: 800/7518 days | 20,763 rows scraped\n",
      "Progress: 900/7518 days | 23,330 rows scraped\n",
      "Progress: 900/7518 days | 23,330 rows scraped\n",
      "Progress: 1000/7518 days | 25,919 rows scraped\n",
      "Progress: 1000/7518 days | 25,919 rows scraped\n",
      "Progress: 1100/7518 days | 28,489 rows scraped\n",
      "Progress: 1100/7518 days | 28,489 rows scraped\n",
      "Progress: 1200/7518 days | 31,119 rows scraped\n",
      "Progress: 1200/7518 days | 31,119 rows scraped\n",
      "Progress: 1300/7518 days | 33,730 rows scraped\n",
      "Progress: 1300/7518 days | 33,730 rows scraped\n",
      "Progress: 1400/7518 days | 36,294 rows scraped\n",
      "Progress: 1400/7518 days | 36,294 rows scraped\n",
      "Progress: 1500/7518 days | 38,845 rows scraped\n",
      "Progress: 1500/7518 days | 38,845 rows scraped\n",
      "Progress: 1600/7518 days | 41,395 rows scraped\n",
      "Progress: 1600/7518 days | 41,395 rows scraped\n",
      "Progress: 1700/7518 days | 44,053 rows scraped\n",
      "Progress: 1700/7518 days | 44,053 rows scraped\n",
      "Progress: 1800/7518 days | 46,690 rows scraped\n",
      "Progress: 1800/7518 days | 46,690 rows scraped\n",
      "Progress: 1900/7518 days | 49,302 rows scraped\n",
      "Progress: 1900/7518 days | 49,302 rows scraped\n",
      "Progress: 2000/7518 days | 52,002 rows scraped\n",
      "Progress: 2000/7518 days | 52,002 rows scraped\n",
      "Progress: 2100/7518 days | 54,608 rows scraped\n",
      "Progress: 2100/7518 days | 54,608 rows scraped\n",
      "Progress: 2200/7518 days | 57,223 rows scraped\n",
      "Progress: 2200/7518 days | 57,223 rows scraped\n",
      "Progress: 2300/7518 days | 59,909 rows scraped\n",
      "Progress: 2300/7518 days | 59,909 rows scraped\n",
      "Progress: 2400/7518 days | 62,548 rows scraped\n",
      "Progress: 2400/7518 days | 62,548 rows scraped\n",
      "Progress: 2500/7518 days | 65,168 rows scraped\n",
      "Progress: 2500/7518 days | 65,168 rows scraped\n",
      "Progress: 2600/7518 days | 67,724 rows scraped\n",
      "Progress: 2600/7518 days | 67,724 rows scraped\n",
      "Progress: 2700/7518 days | 70,320 rows scraped\n",
      "Progress: 2700/7518 days | 70,320 rows scraped\n",
      "Progress: 2800/7518 days | 72,927 rows scraped\n",
      "Progress: 2800/7518 days | 72,927 rows scraped\n",
      "Progress: 2900/7518 days | 75,541 rows scraped\n",
      "Progress: 2900/7518 days | 75,541 rows scraped\n",
      "Progress: 3000/7518 days | 78,208 rows scraped\n",
      "Progress: 3000/7518 days | 78,208 rows scraped\n",
      "Progress: 3100/7518 days | 80,997 rows scraped\n",
      "Progress: 3100/7518 days | 80,997 rows scraped\n",
      "Progress: 3200/7518 days | 83,819 rows scraped\n",
      "Progress: 3200/7518 days | 83,819 rows scraped\n",
      "Progress: 3300/7518 days | 86,227 rows scraped\n",
      "Progress: 3300/7518 days | 86,227 rows scraped\n",
      "Progress: 3400/7518 days | 88,579 rows scraped\n",
      "Progress: 3400/7518 days | 88,579 rows scraped\n",
      "Progress: 3500/7518 days | 90,927 rows scraped\n",
      "Progress: 3500/7518 days | 90,927 rows scraped\n",
      "Progress: 3600/7518 days | 93,480 rows scraped\n",
      "Progress: 3600/7518 days | 93,480 rows scraped\n",
      "Progress: 3700/7518 days | 96,091 rows scraped\n",
      "Progress: 3700/7518 days | 96,091 rows scraped\n",
      "Progress: 3800/7518 days | 98,828 rows scraped\n",
      "Progress: 3800/7518 days | 98,828 rows scraped\n",
      "Progress: 3900/7518 days | 101,555 rows scraped\n",
      "Progress: 3900/7518 days | 101,555 rows scraped\n",
      "Progress: 4000/7518 days | 104,164 rows scraped\n",
      "Progress: 4000/7518 days | 104,164 rows scraped\n",
      "Progress: 4100/7518 days | 106,694 rows scraped\n",
      "Progress: 4100/7518 days | 106,694 rows scraped\n",
      "Progress: 4200/7518 days | 109,348 rows scraped\n",
      "Progress: 4200/7518 days | 109,348 rows scraped\n",
      "Progress: 4300/7518 days | 111,938 rows scraped\n",
      "Progress: 4300/7518 days | 111,938 rows scraped\n",
      "Progress: 4400/7518 days | 114,547 rows scraped\n",
      "Progress: 4400/7518 days | 114,547 rows scraped\n",
      "Progress: 4500/7518 days | 117,167 rows scraped\n",
      "Progress: 4500/7518 days | 117,167 rows scraped\n",
      "Progress: 4600/7518 days | 119,744 rows scraped\n",
      "Progress: 4600/7518 days | 119,744 rows scraped\n",
      "Progress: 4700/7518 days | 122,381 rows scraped\n",
      "Progress: 4700/7518 days | 122,381 rows scraped\n",
      "Progress: 4800/7518 days | 124,986 rows scraped\n",
      "Progress: 4800/7518 days | 124,986 rows scraped\n",
      "Progress: 4900/7518 days | 127,745 rows scraped\n",
      "Progress: 4900/7518 days | 127,745 rows scraped\n",
      "Progress: 5000/7518 days | 130,498 rows scraped\n",
      "Progress: 5000/7518 days | 130,498 rows scraped\n",
      "Progress: 5100/7518 days | 133,110 rows scraped\n",
      "Progress: 5100/7518 days | 133,110 rows scraped\n",
      "Progress: 5200/7518 days | 135,678 rows scraped\n",
      "Progress: 5200/7518 days | 135,678 rows scraped\n",
      "Progress: 5300/7518 days | 138,341 rows scraped\n",
      "Progress: 5300/7518 days | 138,341 rows scraped\n",
      "Progress: 5400/7518 days | 140,972 rows scraped\n",
      "Progress: 5400/7518 days | 140,972 rows scraped\n",
      "Progress: 5500/7518 days | 143,683 rows scraped\n",
      "Progress: 5500/7518 days | 143,683 rows scraped\n",
      "Progress: 5600/7518 days | 146,483 rows scraped\n",
      "Progress: 5600/7518 days | 146,483 rows scraped\n",
      "Progress: 5700/7518 days | 149,299 rows scraped\n",
      "Progress: 5700/7518 days | 149,299 rows scraped\n",
      "Progress: 5800/7518 days | 152,139 rows scraped\n",
      "Progress: 5800/7518 days | 152,139 rows scraped\n",
      "Progress: 5900/7518 days | 154,926 rows scraped\n",
      "Progress: 5900/7518 days | 154,926 rows scraped\n",
      "Progress: 6000/7518 days | 157,633 rows scraped\n",
      "Progress: 6000/7518 days | 157,633 rows scraped\n",
      "Progress: 6100/7518 days | 160,348 rows scraped\n",
      "Progress: 6100/7518 days | 160,348 rows scraped\n",
      "Progress: 6200/7518 days | 163,201 rows scraped\n",
      "Progress: 6200/7518 days | 163,201 rows scraped\n",
      "Progress: 6300/7518 days | 165,983 rows scraped\n",
      "Progress: 6300/7518 days | 165,983 rows scraped\n",
      "Progress: 6400/7518 days | 168,670 rows scraped\n",
      "Progress: 6400/7518 days | 168,670 rows scraped\n",
      "Progress: 6500/7518 days | 171,355 rows scraped\n",
      "Progress: 6500/7518 days | 171,355 rows scraped\n",
      "Progress: 6600/7518 days | 174,075 rows scraped\n",
      "Progress: 6600/7518 days | 174,075 rows scraped\n",
      "Progress: 6700/7518 days | 176,715 rows scraped\n",
      "Progress: 6700/7518 days | 176,715 rows scraped\n",
      "Progress: 6800/7518 days | 179,347 rows scraped\n",
      "Progress: 6800/7518 days | 179,347 rows scraped\n",
      "Progress: 6900/7518 days | 182,041 rows scraped\n",
      "Progress: 6900/7518 days | 182,041 rows scraped\n",
      "Progress: 7000/7518 days | 184,703 rows scraped\n",
      "Progress: 7000/7518 days | 184,703 rows scraped\n",
      "Progress: 7100/7518 days | 187,456 rows scraped\n",
      "Progress: 7100/7518 days | 187,456 rows scraped\n",
      "Progress: 7200/7518 days | 190,075 rows scraped\n",
      "Progress: 7200/7518 days | 190,075 rows scraped\n",
      "Progress: 7300/7518 days | 192,858 rows scraped\n",
      "Progress: 7300/7518 days | 192,858 rows scraped\n",
      "Progress: 7400/7518 days | 195,671 rows scraped\n",
      "Progress: 7400/7518 days | 195,671 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7486/7518 days for KEWR | Total rows: 198,102\n",
      "Running total: 821,024 rows across 4 stations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/2074470647.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all_weather_3 = pd.concat(all_weather_3, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "✓ Scraping complete!\n",
      "==================================================\n",
      "\n",
      "Total rows scraped: 821,024\n",
      "\n",
      "First 5 rows:\n",
      "  obs_id  valid_time_gmt      wx_phrase  temp  precip_hrly  snow_hrly  wspd  \\\n",
      "0   KMSP       560062800  Mostly Cloudy  49.0          NaN        NaN   3.0   \n",
      "1   KMSP       560066400         Cloudy  52.0          NaN        NaN   8.0   \n",
      "2   KMSP       560070000         Cloudy  53.0          NaN        NaN  12.0   \n",
      "3   KMSP       560073600           Fair  52.0          NaN        NaN  12.0   \n",
      "4   KMSP       560077200           Fair  50.0          NaN        NaN   9.0   \n",
      "\n",
      "  clds    rh   vis  \n",
      "0  BKN  69.0  15.0  \n",
      "1  OVC  54.0  10.0  \n",
      "2  OVC  48.0  10.0  \n",
      "3  FEW  47.0  10.0  \n",
      "4  FEW  50.0  10.0  \n",
      "\n",
      "✓ Data saved to: weather_data_list3.csv\n",
      "\n",
      "✓ Data saved to: weather_data_list3.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Scrape weather for all ICAO codes (list 3) - OPTIMIZED ASYNC VERSION ---\n",
    "print(\"Starting async scraping for list 3...\")\n",
    "print(f\"Stations to scrape: {list3}\")\n",
    "\n",
    "# Run the async scraping\n",
    "all_weather_3 = await scrape_all_stations_async(list3, '1987-10-01', '2008-04-30')\n",
    "\n",
    "# Combine all stations into one DataFrame\n",
    "if all_weather_3:\n",
    "    df_all_weather_3 = pd.concat(all_weather_3, ignore_index=True)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ Scraping complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nTotal rows scraped: {len(df_all_weather_3):,}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_all_weather_3.head())\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = 'weather_data_list3.csv'\n",
    "    df_all_weather_3.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n✗ No data was scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42da903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping station: KLAS\n",
      "Scraped data for KLAS on 1987-10-01\n",
      "Scraped data for KLAS on 1987-10-02\n",
      "Scraped data for KLAS on 1987-10-03\n",
      "Scraped data for KLAS on 1987-10-04\n",
      "Scraped data for KLAS on 1987-10-05\n",
      "Scraped data for KLAS on 1987-10-06\n",
      "Scraped data for KLAS on 1987-10-07\n",
      "Scraped data for KLAS on 1987-10-08\n",
      "Scraped data for KLAS on 1987-10-09\n",
      "Scraped data for KLAS on 1987-10-10\n",
      "Scraped data for KLAS on 1987-10-11\n",
      "Scraped data for KLAS on 1987-10-12\n",
      "Scraped data for KLAS on 1987-10-13\n",
      "Scraped data for KLAS on 1987-10-14\n",
      "Scraped data for KLAS on 1987-10-15\n",
      "Scraped data for KLAS on 1987-10-16\n",
      "Scraped data for KLAS on 1987-10-17\n",
      "Scraped data for KLAS on 1987-10-18\n",
      "Scraped data for KLAS on 1987-10-19\n",
      "Scraped data for KLAS on 1987-10-20\n",
      "Scraped data for KLAS on 1987-10-21\n",
      "Scraped data for KLAS on 1987-10-22\n",
      "Scraped data for KLAS on 1987-10-23\n",
      "Scraped data for KLAS on 1987-10-24\n",
      "Scraped data for KLAS on 1987-10-25\n",
      "Scraped data for KLAS on 1987-10-26\n",
      "Scraped data for KLAS on 1987-10-27\n",
      "Scraped data for KLAS on 1987-10-28\n",
      "Scraped data for KLAS on 1987-10-29\n",
      "Scraped data for KLAS on 1987-10-30\n",
      "Scraped data for KLAS on 1987-10-31\n",
      "Scraped data for KLAS on 1987-11-01\n",
      "Scraped data for KLAS on 1987-11-02\n",
      "Scraped data for KLAS on 1987-11-03\n",
      "Scraped data for KLAS on 1987-11-04\n",
      "Scraped data for KLAS on 1987-11-05\n",
      "Scraped data for KLAS on 1987-11-06\n",
      "Scraped data for KLAS on 1987-11-07\n",
      "Scraped data for KLAS on 1987-11-08\n",
      "Scraped data for KLAS on 1987-11-09\n",
      "Scraped data for KLAS on 1987-11-10\n",
      "Scraped data for KLAS on 1987-11-11\n",
      "Scraped data for KLAS on 1987-11-12\n",
      "Scraped data for KLAS on 1987-11-13\n",
      "Scraped data for KLAS on 1987-11-14\n",
      "Scraped data for KLAS on 1987-11-15\n",
      "Scraped data for KLAS on 1987-11-16\n",
      "Scraped data for KLAS on 1987-11-17\n",
      "Scraped data for KLAS on 1987-11-18\n",
      "Scraped data for KLAS on 1987-11-19\n",
      "Scraped data for KLAS on 1987-11-20\n",
      "Scraped data for KLAS on 1987-11-21\n",
      "Scraped data for KLAS on 1987-11-22\n",
      "Scraped data for KLAS on 1987-11-23\n",
      "Scraped data for KLAS on 1987-11-24\n",
      "Scraped data for KLAS on 1987-11-25\n",
      "Scraped data for KLAS on 1987-11-26\n",
      "Scraped data for KLAS on 1987-11-27\n",
      "Scraped data for KLAS on 1987-11-28\n",
      "Scraped data for KLAS on 1987-11-29\n",
      "Scraped data for KLAS on 1987-11-30\n",
      "Scraped data for KLAS on 1987-12-01\n",
      "Scraped data for KLAS on 1987-12-02\n",
      "Scraped data for KLAS on 1987-12-03\n",
      "Scraped data for KLAS on 1987-12-04\n",
      "Scraped data for KLAS on 1987-12-05\n",
      "Scraped data for KLAS on 1987-12-06\n",
      "Scraped data for KLAS on 1987-12-07\n",
      "Scraped data for KLAS on 1987-12-08\n",
      "Scraped data for KLAS on 1987-12-09\n",
      "Scraped data for KLAS on 1987-12-10\n",
      "Scraped data for KLAS on 1987-12-11\n",
      "Scraped data for KLAS on 1987-12-12\n",
      "Scraped data for KLAS on 1987-12-13\n",
      "Scraped data for KLAS on 1987-12-14\n",
      "Scraped data for KLAS on 1987-12-15\n",
      "Scraped data for KLAS on 1987-12-16\n",
      "Scraped data for KLAS on 1987-12-17\n",
      "Scraped data for KLAS on 1987-12-18\n",
      "Scraped data for KLAS on 1987-12-19\n",
      "Scraped data for KLAS on 1987-12-20\n",
      "Scraped data for KLAS on 1987-12-21\n",
      "Scraped data for KLAS on 1987-12-22\n",
      "Scraped data for KLAS on 1987-12-23\n",
      "Scraped data for KLAS on 1987-12-24\n",
      "Scraped data for KLAS on 1987-12-25\n",
      "Scraped data for KLAS on 1987-12-26\n",
      "Scraped data for KLAS on 1987-12-27\n",
      "Scraped data for KLAS on 1987-12-28\n",
      "Scraped data for KLAS on 1987-12-29\n",
      "Scraped data for KLAS on 1987-12-30\n",
      "Scraped data for KLAS on 1987-12-31\n",
      "Skipping KLAS on 1988-01-01 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-02 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-03 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-04 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-05 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-06 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-07 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-08 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-09 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-10 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-11 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-12 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-13 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-14 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-15 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-16 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-17 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-18 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-19 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-20 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-21 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-22 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-23 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-24 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-25 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-26 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-27 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-28 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-29 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-30 due to error: 'observations'\n",
      "Skipping KLAS on 1988-01-31 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-01 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-02 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-03 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-04 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-05 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-06 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-07 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-08 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-09 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-10 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-11 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-12 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-13 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-14 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-15 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-16 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-17 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-18 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-19 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-20 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-21 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-22 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-23 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-24 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-25 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-26 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-27 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-28 due to error: 'observations'\n",
      "Skipping KLAS on 1988-02-29 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-01 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-02 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-03 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-04 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-05 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-06 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-07 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-08 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-09 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-10 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-11 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-12 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-13 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-14 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-15 due to error: 'observations'\n",
      "Skipping KLAS on 1988-03-16 due to error: 'observations'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m station \u001b[38;5;129;01min\u001b[39;00m list4:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping station: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df_weather_4 = \u001b[43mscrape_multidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1987-10-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2008-04-30\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_weather_4.empty:\n\u001b[32m      8\u001b[39m         all_weather_4.append(df_weather_4)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mscrape_multidate\u001b[39m\u001b[34m(station, start_date, end_date)\u001b[39m\n\u001b[32m     19\u001b[39m date_str = date.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     df_day = \u001b[43mscrape_wunderground\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_day.empty:\n\u001b[32m     23\u001b[39m         df_list.append(df_day)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mscrape_wunderground\u001b[39m\u001b[34m(station, date)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscrape_wunderground\u001b[39m(station, date):\n\u001b[32m      2\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.weather.com/v1/location/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:9:US/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=e&startDate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate.replace(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     data = response.json()\n\u001b[32m      5\u001b[39m     df = pd.DataFrame(data[\u001b[33m\"\u001b[39m\u001b[33mobservations\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DELETE/IS459-Project/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Scrape weather for all ICAO codes (list 4) - OPTIMIZED ASYNC VERSION ---\n",
    "print(\"Starting async scraping for list 4...\")\n",
    "print(f\"Stations to scrape: {list4}\")\n",
    "\n",
    "# Run the async scraping\n",
    "all_weather_4 = await scrape_all_stations_async(list4, '1987-10-01', '2008-04-30')\n",
    "\n",
    "# Combine all stations into one DataFrame\n",
    "if all_weather_4:\n",
    "    df_all_weather_4 = pd.concat(all_weather_4, ignore_index=True)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ Scraping complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nTotal rows scraped: {len(df_all_weather_4):,}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_all_weather_4.head())\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = 'weather_data_list4.csv'\n",
    "    df_all_weather_4.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n✗ No data was scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting async scraping for list 5...\n",
      "Stations to scrape: ['KPHL', 'KPIT', 'KSLC', 'KSEA']\n",
      "\n",
      "============================================================\n",
      "Station 1/4: KPHL\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KPHL...\n",
      "Progress: 100/7518 days | 2,662 rows scraped\n",
      "Progress: 100/7518 days | 2,662 rows scraped\n",
      "Progress: 200/7518 days | 5,341 rows scraped\n",
      "Progress: 200/7518 days | 5,341 rows scraped\n",
      "Progress: 300/7518 days | 8,029 rows scraped\n",
      "Progress: 300/7518 days | 8,029 rows scraped\n",
      "Progress: 400/7518 days | 10,659 rows scraped\n",
      "Progress: 400/7518 days | 10,659 rows scraped\n",
      "Progress: 500/7518 days | 13,427 rows scraped\n",
      "Progress: 500/7518 days | 13,427 rows scraped\n",
      "Progress: 600/7518 days | 16,215 rows scraped\n",
      "Progress: 600/7518 days | 16,215 rows scraped\n",
      "Progress: 700/7518 days | 19,054 rows scraped\n",
      "Progress: 700/7518 days | 19,054 rows scraped\n",
      "Progress: 800/7518 days | 21,865 rows scraped\n",
      "Progress: 800/7518 days | 21,865 rows scraped\n",
      "Progress: 900/7518 days | 24,572 rows scraped\n",
      "Progress: 900/7518 days | 24,572 rows scraped\n",
      "Progress: 1000/7518 days | 27,328 rows scraped\n",
      "Progress: 1000/7518 days | 27,328 rows scraped\n",
      "Progress: 1100/7518 days | 30,044 rows scraped\n",
      "Progress: 1100/7518 days | 30,044 rows scraped\n",
      "Progress: 1200/7518 days | 32,786 rows scraped\n",
      "Progress: 1200/7518 days | 32,786 rows scraped\n",
      "Progress: 1300/7518 days | 35,560 rows scraped\n",
      "Progress: 1300/7518 days | 35,560 rows scraped\n",
      "Progress: 1400/7518 days | 38,162 rows scraped\n",
      "Progress: 1400/7518 days | 38,162 rows scraped\n",
      "Progress: 1500/7518 days | 40,783 rows scraped\n",
      "Progress: 1500/7518 days | 40,783 rows scraped\n",
      "Progress: 1600/7518 days | 43,470 rows scraped\n",
      "Progress: 1600/7518 days | 43,470 rows scraped\n",
      "Progress: 1700/7518 days | 46,193 rows scraped\n",
      "Progress: 1700/7518 days | 46,193 rows scraped\n",
      "Progress: 1800/7518 days | 48,832 rows scraped\n",
      "Progress: 1900/7518 days | 51,453 rows scraped\n",
      "Progress: 2000/7518 days | 54,199 rows scraped\n",
      "Progress: 2100/7518 days | 56,815 rows scraped\n",
      "Progress: 2200/7518 days | 59,442 rows scraped\n",
      "Progress: 2300/7518 days | 62,054 rows scraped\n",
      "Progress: 2400/7518 days | 64,780 rows scraped\n",
      "Progress: 1800/7518 days | 48,832 rows scraped\n",
      "Progress: 1900/7518 days | 51,453 rows scraped\n",
      "Progress: 2000/7518 days | 54,199 rows scraped\n",
      "Progress: 2100/7518 days | 56,815 rows scraped\n",
      "Progress: 2200/7518 days | 59,442 rows scraped\n",
      "Progress: 2300/7518 days | 62,054 rows scraped\n",
      "Progress: 2400/7518 days | 64,780 rows scraped\n",
      "Progress: 2500/7518 days | 67,463 rows scraped\n",
      "Progress: 2500/7518 days | 67,463 rows scraped\n",
      "Progress: 2600/7518 days | 70,068 rows scraped\n",
      "Progress: 2600/7518 days | 70,068 rows scraped\n",
      "Progress: 2700/7518 days | 72,701 rows scraped\n",
      "Progress: 2700/7518 days | 72,701 rows scraped\n",
      "Progress: 2800/7518 days | 75,330 rows scraped\n",
      "Progress: 2800/7518 days | 75,330 rows scraped\n",
      "Progress: 2900/7518 days | 77,955 rows scraped\n",
      "Progress: 2900/7518 days | 77,955 rows scraped\n",
      "Progress: 3000/7518 days | 80,627 rows scraped\n",
      "Progress: 3000/7518 days | 80,627 rows scraped\n",
      "Progress: 3100/7518 days | 83,447 rows scraped\n",
      "Progress: 3100/7518 days | 83,447 rows scraped\n",
      "Progress: 3200/7518 days | 86,324 rows scraped\n",
      "Progress: 3200/7518 days | 86,324 rows scraped\n",
      "Progress: 3300/7518 days | 88,724 rows scraped\n",
      "Progress: 3300/7518 days | 88,724 rows scraped\n",
      "Progress: 3400/7518 days | 91,095 rows scraped\n",
      "Progress: 3400/7518 days | 91,095 rows scraped\n",
      "Progress: 3500/7518 days | 93,457 rows scraped\n",
      "Progress: 3500/7518 days | 93,457 rows scraped\n",
      "Progress: 3600/7518 days | 95,991 rows scraped\n",
      "Progress: 3600/7518 days | 95,991 rows scraped\n",
      "Progress: 3700/7518 days | 98,621 rows scraped\n",
      "Progress: 3700/7518 days | 98,621 rows scraped\n",
      "Progress: 3800/7518 days | 101,330 rows scraped\n",
      "Progress: 3800/7518 days | 101,330 rows scraped\n",
      "Progress: 3900/7518 days | 104,069 rows scraped\n",
      "Progress: 3900/7518 days | 104,069 rows scraped\n",
      "Progress: 4000/7518 days | 106,693 rows scraped\n",
      "Progress: 4000/7518 days | 106,693 rows scraped\n",
      "Progress: 4100/7518 days | 109,248 rows scraped\n",
      "Progress: 4100/7518 days | 109,248 rows scraped\n",
      "Progress: 4200/7518 days | 111,958 rows scraped\n",
      "Progress: 4200/7518 days | 111,958 rows scraped\n",
      "Progress: 4300/7518 days | 114,627 rows scraped\n",
      "Progress: 4300/7518 days | 114,627 rows scraped\n",
      "Progress: 4400/7518 days | 117,392 rows scraped\n",
      "Progress: 4400/7518 days | 117,392 rows scraped\n",
      "Progress: 4500/7518 days | 120,002 rows scraped\n",
      "Progress: 4500/7518 days | 120,002 rows scraped\n",
      "Progress: 4600/7518 days | 122,615 rows scraped\n",
      "Progress: 4600/7518 days | 122,615 rows scraped\n",
      "Progress: 4700/7518 days | 125,282 rows scraped\n",
      "Progress: 4700/7518 days | 125,282 rows scraped\n",
      "Progress: 4800/7518 days | 127,963 rows scraped\n",
      "Progress: 4800/7518 days | 127,963 rows scraped\n",
      "Progress: 4900/7518 days | 130,756 rows scraped\n",
      "Progress: 4900/7518 days | 130,756 rows scraped\n",
      "Progress: 5000/7518 days | 133,532 rows scraped\n",
      "Progress: 5000/7518 days | 133,532 rows scraped\n",
      "Progress: 5100/7518 days | 136,220 rows scraped\n",
      "Progress: 5100/7518 days | 136,220 rows scraped\n",
      "Progress: 5200/7518 days | 138,851 rows scraped\n",
      "Progress: 5200/7518 days | 138,851 rows scraped\n",
      "Progress: 5300/7518 days | 141,551 rows scraped\n",
      "Progress: 5400/7518 days | 144,233 rows scraped\n",
      "Progress: 5500/7518 days | 146,906 rows scraped\n",
      "Progress: 5600/7518 days | 149,875 rows scraped\n",
      "Progress: 5700/7518 days | 152,735 rows scraped\n",
      "Progress: 5800/7518 days | 155,797 rows scraped\n",
      "Progress: 5900/7518 days | 158,646 rows scraped\n",
      "Progress: 6000/7518 days | 161,445 rows scraped\n",
      "Progress: 6100/7518 days | 164,162 rows scraped\n",
      "Progress: 6200/7518 days | 167,148 rows scraped\n",
      "Progress: 6300/7518 days | 169,928 rows scraped\n",
      "Progress: 6400/7518 days | 172,741 rows scraped\n",
      "Progress: 6500/7518 days | 175,605 rows scraped\n",
      "Progress: 6600/7518 days | 178,337 rows scraped\n",
      "Progress: 6700/7518 days | 181,112 rows scraped\n",
      "Progress: 6800/7518 days | 183,733 rows scraped\n",
      "Progress: 6900/7518 days | 186,578 rows scraped\n",
      "Progress: 7000/7518 days | 189,379 rows scraped\n",
      "Progress: 7100/7518 days | 192,234 rows scraped\n",
      "Progress: 7200/7518 days | 194,994 rows scraped\n",
      "Progress: 7300/7518 days | 197,911 rows scraped\n",
      "Progress: 7400/7518 days | 200,952 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7487/7518 days for KPHL | Total rows: 203,783\n",
      "Running total: 203,783 rows across 1 stations\n",
      "\n",
      "============================================================\n",
      "Station 2/4: KPIT\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KPIT...\n",
      "\n",
      "============================================================\n",
      "Station 2/4: KPIT\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KPIT...\n",
      "Progress: 100/7518 days | 2,958 rows scraped\n",
      "Progress: 100/7518 days | 2,958 rows scraped\n",
      "Progress: 200/7518 days | 5,980 rows scraped\n",
      "Progress: 200/7518 days | 5,980 rows scraped\n",
      "Progress: 300/7518 days | 8,672 rows scraped\n",
      "Progress: 300/7518 days | 8,672 rows scraped\n",
      "Progress: 400/7518 days | 11,509 rows scraped\n",
      "Progress: 400/7518 days | 11,509 rows scraped\n",
      "Progress: 500/7518 days | 14,374 rows scraped\n",
      "Progress: 500/7518 days | 14,374 rows scraped\n",
      "Progress: 600/7518 days | 17,310 rows scraped\n",
      "Progress: 600/7518 days | 17,310 rows scraped\n",
      "Progress: 700/7518 days | 20,151 rows scraped\n",
      "Progress: 700/7518 days | 20,151 rows scraped\n",
      "Progress: 800/7518 days | 22,976 rows scraped\n",
      "Progress: 800/7518 days | 22,976 rows scraped\n",
      "Progress: 900/7518 days | 25,828 rows scraped\n",
      "Progress: 900/7518 days | 25,828 rows scraped\n",
      "Progress: 1000/7518 days | 28,569 rows scraped\n",
      "Progress: 1000/7518 days | 28,569 rows scraped\n",
      "Progress: 1100/7518 days | 31,383 rows scraped\n",
      "Progress: 1100/7518 days | 31,383 rows scraped\n",
      "Progress: 1200/7518 days | 34,202 rows scraped\n",
      "Progress: 1200/7518 days | 34,202 rows scraped\n",
      "Progress: 1300/7518 days | 37,064 rows scraped\n",
      "Progress: 1300/7518 days | 37,064 rows scraped\n",
      "Progress: 1400/7518 days | 39,648 rows scraped\n",
      "Progress: 1400/7518 days | 39,648 rows scraped\n",
      "Progress: 1500/7518 days | 42,276 rows scraped\n",
      "Progress: 1500/7518 days | 42,276 rows scraped\n",
      "Progress: 1600/7518 days | 45,181 rows scraped\n",
      "Progress: 1600/7518 days | 45,181 rows scraped\n",
      "Progress: 1700/7518 days | 47,933 rows scraped\n",
      "Progress: 1700/7518 days | 47,933 rows scraped\n",
      "Progress: 1800/7518 days | 50,730 rows scraped\n",
      "Progress: 1800/7518 days | 50,730 rows scraped\n",
      "Progress: 1900/7518 days | 53,463 rows scraped\n",
      "Progress: 1900/7518 days | 53,463 rows scraped\n",
      "Progress: 2000/7518 days | 56,380 rows scraped\n",
      "Progress: 2000/7518 days | 56,380 rows scraped\n",
      "Progress: 2100/7518 days | 58,990 rows scraped\n",
      "Progress: 2100/7518 days | 58,990 rows scraped\n",
      "Progress: 2200/7518 days | 61,690 rows scraped\n",
      "Progress: 2200/7518 days | 61,690 rows scraped\n",
      "Progress: 2300/7518 days | 64,546 rows scraped\n",
      "Progress: 2300/7518 days | 64,546 rows scraped\n",
      "Progress: 2400/7518 days | 67,371 rows scraped\n",
      "Progress: 2400/7518 days | 67,371 rows scraped\n",
      "Progress: 2500/7518 days | 70,091 rows scraped\n",
      "Progress: 2500/7518 days | 70,091 rows scraped\n",
      "Progress: 2600/7518 days | 72,692 rows scraped\n",
      "Progress: 2600/7518 days | 72,692 rows scraped\n",
      "Progress: 2700/7518 days | 75,513 rows scraped\n",
      "Progress: 2700/7518 days | 75,513 rows scraped\n",
      "Progress: 2800/7518 days | 78,184 rows scraped\n",
      "Progress: 2800/7518 days | 78,184 rows scraped\n",
      "Progress: 2900/7518 days | 80,826 rows scraped\n",
      "Progress: 2900/7518 days | 80,826 rows scraped\n",
      "Progress: 3000/7518 days | 83,572 rows scraped\n",
      "Progress: 3000/7518 days | 83,572 rows scraped\n",
      "Progress: 3100/7518 days | 86,573 rows scraped\n",
      "Progress: 3100/7518 days | 86,573 rows scraped\n",
      "Progress: 3200/7518 days | 89,363 rows scraped\n",
      "Progress: 3200/7518 days | 89,363 rows scraped\n",
      "Progress: 3300/7518 days | 91,753 rows scraped\n",
      "Progress: 3300/7518 days | 91,753 rows scraped\n",
      "Progress: 3400/7518 days | 94,131 rows scraped\n",
      "Progress: 3400/7518 days | 94,131 rows scraped\n",
      "Progress: 3500/7518 days | 96,490 rows scraped\n",
      "Progress: 3500/7518 days | 96,490 rows scraped\n",
      "Progress: 3600/7518 days | 99,185 rows scraped\n",
      "Progress: 3600/7518 days | 99,185 rows scraped\n",
      "Progress: 3700/7518 days | 102,046 rows scraped\n",
      "Progress: 3700/7518 days | 102,046 rows scraped\n",
      "Progress: 3800/7518 days | 105,097 rows scraped\n",
      "Progress: 3800/7518 days | 105,097 rows scraped\n",
      "Progress: 3900/7518 days | 108,062 rows scraped\n",
      "Progress: 3900/7518 days | 108,062 rows scraped\n",
      "Progress: 4000/7518 days | 110,852 rows scraped\n",
      "Progress: 4000/7518 days | 110,852 rows scraped\n",
      "Progress: 4100/7518 days | 113,552 rows scraped\n",
      "Progress: 4100/7518 days | 113,552 rows scraped\n",
      "Progress: 4200/7518 days | 116,676 rows scraped\n",
      "Progress: 4200/7518 days | 116,676 rows scraped\n",
      "Progress: 4300/7518 days | 119,439 rows scraped\n",
      "Progress: 4300/7518 days | 119,439 rows scraped\n",
      "Progress: 4400/7518 days | 122,156 rows scraped\n",
      "Progress: 4400/7518 days | 122,156 rows scraped\n",
      "Progress: 4500/7518 days | 125,117 rows scraped\n",
      "Progress: 4500/7518 days | 125,117 rows scraped\n",
      "Progress: 4600/7518 days | 127,840 rows scraped\n",
      "Progress: 4600/7518 days | 127,840 rows scraped\n",
      "Progress: 4700/7518 days | 130,619 rows scraped\n",
      "Progress: 4700/7518 days | 130,619 rows scraped\n",
      "Progress: 4800/7518 days | 133,638 rows scraped\n",
      "Progress: 4800/7518 days | 133,638 rows scraped\n",
      "Progress: 4900/7518 days | 136,745 rows scraped\n",
      "Progress: 4900/7518 days | 136,745 rows scraped\n",
      "Progress: 5000/7518 days | 139,548 rows scraped\n",
      "Progress: 5000/7518 days | 139,548 rows scraped\n",
      "Progress: 5100/7518 days | 142,238 rows scraped\n",
      "Progress: 5100/7518 days | 142,238 rows scraped\n",
      "Progress: 5200/7518 days | 145,074 rows scraped\n",
      "Progress: 5200/7518 days | 145,074 rows scraped\n",
      "Progress: 5300/7518 days | 147,980 rows scraped\n",
      "Progress: 5300/7518 days | 147,980 rows scraped\n",
      "Progress: 5400/7518 days | 150,663 rows scraped\n",
      "Progress: 5400/7518 days | 150,663 rows scraped\n",
      "Progress: 5500/7518 days | 153,446 rows scraped\n",
      "Progress: 5500/7518 days | 153,446 rows scraped\n",
      "Progress: 5600/7518 days | 156,588 rows scraped\n",
      "Progress: 5600/7518 days | 156,588 rows scraped\n",
      "Progress: 5700/7518 days | 159,400 rows scraped\n",
      "Progress: 5700/7518 days | 159,400 rows scraped\n",
      "Progress: 5800/7518 days | 162,266 rows scraped\n",
      "Progress: 5800/7518 days | 162,266 rows scraped\n",
      "Progress: 5900/7518 days | 165,160 rows scraped\n",
      "Progress: 5900/7518 days | 165,160 rows scraped\n",
      "Progress: 6000/7518 days | 168,172 rows scraped\n",
      "Progress: 6000/7518 days | 168,172 rows scraped\n",
      "Progress: 6100/7518 days | 170,748 rows scraped\n",
      "Progress: 6100/7518 days | 170,748 rows scraped\n",
      "Progress: 6200/7518 days | 173,549 rows scraped\n",
      "Progress: 6200/7518 days | 173,549 rows scraped\n",
      "Progress: 6300/7518 days | 176,461 rows scraped\n",
      "Progress: 6300/7518 days | 176,461 rows scraped\n",
      "Progress: 6400/7518 days | 179,379 rows scraped\n",
      "Progress: 6400/7518 days | 179,379 rows scraped\n",
      "Progress: 6500/7518 days | 181,967 rows scraped\n",
      "Progress: 6500/7518 days | 181,967 rows scraped\n",
      "Progress: 6600/7518 days | 184,652 rows scraped\n",
      "Progress: 6600/7518 days | 184,652 rows scraped\n",
      "Progress: 6700/7518 days | 187,483 rows scraped\n",
      "Progress: 6700/7518 days | 187,483 rows scraped\n",
      "Progress: 6800/7518 days | 190,122 rows scraped\n",
      "Progress: 6800/7518 days | 190,122 rows scraped\n",
      "Progress: 6900/7518 days | 192,908 rows scraped\n",
      "Progress: 6900/7518 days | 192,908 rows scraped\n",
      "Progress: 7000/7518 days | 195,577 rows scraped\n",
      "Progress: 7000/7518 days | 195,577 rows scraped\n",
      "Progress: 7100/7518 days | 198,654 rows scraped\n",
      "Progress: 7100/7518 days | 198,654 rows scraped\n",
      "Progress: 7200/7518 days | 201,253 rows scraped\n",
      "Progress: 7200/7518 days | 201,253 rows scraped\n",
      "Progress: 7300/7518 days | 203,976 rows scraped\n",
      "Progress: 7300/7518 days | 203,976 rows scraped\n",
      "Progress: 7400/7518 days | 206,943 rows scraped\n",
      "Progress: 7400/7518 days | 206,943 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7485/7518 days for KPIT | Total rows: 209,444\n",
      "Running total: 413,227 rows across 2 stations\n",
      "\n",
      "============================================================\n",
      "Station 3/4: KSLC\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSLC...\n",
      "\n",
      "============================================================\n",
      "Station 3/4: KSLC\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSLC...\n",
      "Progress: 100/7518 days | 2,573 rows scraped\n",
      "Progress: 100/7518 days | 2,573 rows scraped\n",
      "Progress: 200/7518 days | 5,207 rows scraped\n",
      "Progress: 200/7518 days | 5,207 rows scraped\n",
      "Progress: 300/7518 days | 7,702 rows scraped\n",
      "Progress: 300/7518 days | 7,702 rows scraped\n",
      "Progress: 400/7518 days | 10,160 rows scraped\n",
      "Progress: 400/7518 days | 10,160 rows scraped\n",
      "Progress: 500/7518 days | 13,061 rows scraped\n",
      "Progress: 500/7518 days | 13,061 rows scraped\n",
      "Progress: 600/7518 days | 15,641 rows scraped\n",
      "Progress: 600/7518 days | 15,641 rows scraped\n",
      "Progress: 700/7518 days | 18,131 rows scraped\n",
      "Progress: 700/7518 days | 18,131 rows scraped\n",
      "Progress: 800/7518 days | 20,686 rows scraped\n",
      "Progress: 800/7518 days | 20,686 rows scraped\n",
      "Progress: 900/7518 days | 23,308 rows scraped\n",
      "Progress: 900/7518 days | 23,308 rows scraped\n",
      "Progress: 1000/7518 days | 25,772 rows scraped\n",
      "Progress: 1000/7518 days | 25,772 rows scraped\n",
      "Progress: 1100/7518 days | 28,236 rows scraped\n",
      "Progress: 1100/7518 days | 28,236 rows scraped\n",
      "Progress: 1200/7518 days | 30,924 rows scraped\n",
      "Progress: 1200/7518 days | 30,924 rows scraped\n",
      "Progress: 1300/7518 days | 33,535 rows scraped\n",
      "Progress: 1300/7518 days | 33,535 rows scraped\n",
      "Progress: 1400/7518 days | 36,055 rows scraped\n",
      "Progress: 1400/7518 days | 36,055 rows scraped\n",
      "Progress: 1500/7518 days | 38,546 rows scraped\n",
      "Progress: 1500/7518 days | 38,546 rows scraped\n",
      "Progress: 1600/7518 days | 41,468 rows scraped\n",
      "Progress: 1600/7518 days | 41,468 rows scraped\n",
      "Progress: 1700/7518 days | 43,962 rows scraped\n",
      "Progress: 1700/7518 days | 43,962 rows scraped\n",
      "Progress: 1800/7518 days | 46,422 rows scraped\n",
      "Progress: 1800/7518 days | 46,422 rows scraped\n",
      "Progress: 1900/7518 days | 48,971 rows scraped\n",
      "Progress: 1900/7518 days | 48,971 rows scraped\n",
      "Progress: 2000/7518 days | 51,824 rows scraped\n",
      "Progress: 2000/7518 days | 51,824 rows scraped\n",
      "Progress: 2100/7518 days | 54,329 rows scraped\n",
      "Progress: 2100/7518 days | 54,329 rows scraped\n",
      "Progress: 2200/7518 days | 56,791 rows scraped\n",
      "Progress: 2200/7518 days | 56,791 rows scraped\n",
      "Progress: 2300/7518 days | 59,303 rows scraped\n",
      "Progress: 2300/7518 days | 59,303 rows scraped\n",
      "Progress: 2400/7518 days | 61,834 rows scraped\n",
      "Progress: 2400/7518 days | 61,834 rows scraped\n",
      "Progress: 2500/7518 days | 64,277 rows scraped\n",
      "Progress: 2500/7518 days | 64,277 rows scraped\n",
      "Progress: 2600/7518 days | 66,722 rows scraped\n",
      "Progress: 2600/7518 days | 66,722 rows scraped\n",
      "Progress: 2700/7518 days | 69,376 rows scraped\n",
      "Progress: 2700/7518 days | 69,376 rows scraped\n",
      "Progress: 2800/7518 days | 71,892 rows scraped\n",
      "Progress: 2800/7518 days | 71,892 rows scraped\n",
      "Progress: 2900/7518 days | 74,353 rows scraped\n",
      "Progress: 2900/7518 days | 74,353 rows scraped\n",
      "Progress: 3000/7518 days | 76,812 rows scraped\n",
      "Progress: 3000/7518 days | 76,812 rows scraped\n",
      "Progress: 3100/7518 days | 79,532 rows scraped\n",
      "Progress: 3100/7518 days | 79,532 rows scraped\n",
      "Progress: 3200/7518 days | 82,018 rows scraped\n",
      "Progress: 3200/7518 days | 82,018 rows scraped\n",
      "Progress: 3300/7518 days | 84,377 rows scraped\n",
      "Progress: 3300/7518 days | 84,377 rows scraped\n",
      "Progress: 3400/7518 days | 86,761 rows scraped\n",
      "Progress: 3400/7518 days | 86,761 rows scraped\n",
      "Progress: 3500/7518 days | 89,154 rows scraped\n",
      "Progress: 3500/7518 days | 89,154 rows scraped\n",
      "Progress: 3600/7518 days | 91,595 rows scraped\n",
      "Progress: 3600/7518 days | 91,595 rows scraped\n",
      "Progress: 3700/7518 days | 94,032 rows scraped\n",
      "Progress: 3700/7518 days | 94,032 rows scraped\n",
      "Progress: 3800/7518 days | 96,625 rows scraped\n",
      "Progress: 3800/7518 days | 96,625 rows scraped\n",
      "Progress: 3900/7518 days | 99,424 rows scraped\n",
      "Progress: 3900/7518 days | 99,424 rows scraped\n",
      "Progress: 4000/7518 days | 101,981 rows scraped\n",
      "Progress: 4000/7518 days | 101,981 rows scraped\n",
      "Progress: 4100/7518 days | 104,613 rows scraped\n",
      "Progress: 4100/7518 days | 104,613 rows scraped\n",
      "Progress: 4200/7518 days | 107,296 rows scraped\n",
      "Progress: 4200/7518 days | 107,296 rows scraped\n",
      "Progress: 4300/7518 days | 109,923 rows scraped\n",
      "Progress: 4300/7518 days | 109,923 rows scraped\n",
      "Progress: 4400/7518 days | 112,370 rows scraped\n",
      "Progress: 4400/7518 days | 112,370 rows scraped\n",
      "Progress: 4500/7518 days | 115,104 rows scraped\n",
      "Progress: 4500/7518 days | 115,104 rows scraped\n",
      "Progress: 4600/7518 days | 117,712 rows scraped\n",
      "Progress: 4600/7518 days | 117,712 rows scraped\n",
      "Progress: 4700/7518 days | 120,043 rows scraped\n",
      "Progress: 4700/7518 days | 120,043 rows scraped\n",
      "Progress: 4800/7518 days | 122,785 rows scraped\n",
      "Progress: 4800/7518 days | 122,785 rows scraped\n",
      "Progress: 4900/7518 days | 125,878 rows scraped\n",
      "Progress: 4900/7518 days | 125,878 rows scraped\n",
      "Progress: 5000/7518 days | 128,464 rows scraped\n",
      "Progress: 5000/7518 days | 128,464 rows scraped\n",
      "Progress: 5100/7518 days | 130,934 rows scraped\n",
      "Progress: 5100/7518 days | 130,934 rows scraped\n",
      "Progress: 5200/7518 days | 134,184 rows scraped\n",
      "Progress: 5200/7518 days | 134,184 rows scraped\n",
      "Progress: 5300/7518 days | 136,988 rows scraped\n",
      "Progress: 5300/7518 days | 136,988 rows scraped\n",
      "Progress: 5400/7518 days | 139,480 rows scraped\n",
      "Progress: 5400/7518 days | 139,480 rows scraped\n",
      "Progress: 5500/7518 days | 142,045 rows scraped\n",
      "Progress: 5500/7518 days | 142,045 rows scraped\n",
      "Progress: 5600/7518 days | 144,820 rows scraped\n",
      "Progress: 5600/7518 days | 144,820 rows scraped\n",
      "Progress: 5700/7518 days | 147,548 rows scraped\n",
      "Progress: 5700/7518 days | 147,548 rows scraped\n",
      "Progress: 5800/7518 days | 150,022 rows scraped\n",
      "Progress: 5800/7518 days | 150,022 rows scraped\n",
      "Progress: 5900/7518 days | 152,844 rows scraped\n",
      "Progress: 5900/7518 days | 152,844 rows scraped\n",
      "Progress: 6000/7518 days | 155,992 rows scraped\n",
      "Progress: 6000/7518 days | 155,992 rows scraped\n",
      "Progress: 6100/7518 days | 158,358 rows scraped\n",
      "Progress: 6100/7518 days | 158,358 rows scraped\n",
      "Progress: 6200/7518 days | 160,855 rows scraped\n",
      "Progress: 6200/7518 days | 160,855 rows scraped\n",
      "Progress: 6300/7518 days | 163,696 rows scraped\n",
      "Progress: 6300/7518 days | 163,696 rows scraped\n",
      "Progress: 6400/7518 days | 166,435 rows scraped\n",
      "Progress: 6400/7518 days | 166,435 rows scraped\n",
      "Progress: 6500/7518 days | 168,981 rows scraped\n",
      "Progress: 6500/7518 days | 168,981 rows scraped\n",
      "Progress: 6600/7518 days | 171,463 rows scraped\n",
      "Progress: 6600/7518 days | 171,463 rows scraped\n",
      "Progress: 6700/7518 days | 174,324 rows scraped\n",
      "Progress: 6700/7518 days | 174,324 rows scraped\n",
      "Progress: 6800/7518 days | 176,957 rows scraped\n",
      "Progress: 6800/7518 days | 176,957 rows scraped\n",
      "Progress: 6900/7518 days | 179,515 rows scraped\n",
      "Progress: 6900/7518 days | 179,515 rows scraped\n",
      "Progress: 7000/7518 days | 182,129 rows scraped\n",
      "Progress: 7000/7518 days | 182,129 rows scraped\n",
      "Progress: 7100/7518 days | 184,933 rows scraped\n",
      "Progress: 7100/7518 days | 184,933 rows scraped\n",
      "Progress: 7200/7518 days | 187,446 rows scraped\n",
      "Progress: 7200/7518 days | 187,446 rows scraped\n",
      "Progress: 7300/7518 days | 189,970 rows scraped\n",
      "Progress: 7300/7518 days | 189,970 rows scraped\n",
      "Progress: 7400/7518 days | 192,925 rows scraped\n",
      "Progress: 7400/7518 days | 192,925 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7488/7518 days for KSLC | Total rows: 195,345\n",
      "Running total: 608,572 rows across 3 stations\n",
      "\n",
      "============================================================\n",
      "Station 4/4: KSEA\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSEA...\n",
      "\n",
      "============================================================\n",
      "Station 4/4: KSEA\n",
      "============================================================\n",
      "Starting to scrape 7518 days for KSEA...\n",
      "Progress: 100/7518 days | 2,903 rows scraped\n",
      "Progress: 100/7518 days | 2,903 rows scraped\n",
      "Progress: 200/7518 days | 5,913 rows scraped\n",
      "Progress: 200/7518 days | 5,913 rows scraped\n",
      "Progress: 300/7518 days | 8,634 rows scraped\n",
      "Progress: 300/7518 days | 8,634 rows scraped\n",
      "Progress: 400/7518 days | 11,564 rows scraped\n",
      "Progress: 400/7518 days | 11,564 rows scraped\n",
      "Progress: 500/7518 days | 14,660 rows scraped\n",
      "Progress: 500/7518 days | 14,660 rows scraped\n",
      "Progress: 600/7518 days | 17,589 rows scraped\n",
      "Progress: 600/7518 days | 17,589 rows scraped\n",
      "Progress: 700/7518 days | 20,253 rows scraped\n",
      "Progress: 700/7518 days | 20,253 rows scraped\n",
      "Progress: 800/7518 days | 23,187 rows scraped\n",
      "Progress: 800/7518 days | 23,187 rows scraped\n",
      "Progress: 900/7518 days | 26,381 rows scraped\n",
      "Progress: 900/7518 days | 26,381 rows scraped\n",
      "Progress: 1000/7518 days | 29,238 rows scraped\n",
      "Progress: 1000/7518 days | 29,238 rows scraped\n",
      "Progress: 1100/7518 days | 31,945 rows scraped\n",
      "Progress: 1100/7518 days | 31,945 rows scraped\n",
      "Progress: 1200/7518 days | 35,089 rows scraped\n",
      "Progress: 1200/7518 days | 35,089 rows scraped\n",
      "Progress: 1300/7518 days | 38,101 rows scraped\n",
      "Progress: 1300/7518 days | 38,101 rows scraped\n",
      "Progress: 1400/7518 days | 40,830 rows scraped\n",
      "Progress: 1400/7518 days | 40,830 rows scraped\n",
      "Progress: 1500/7518 days | 43,637 rows scraped\n",
      "Progress: 1500/7518 days | 43,637 rows scraped\n",
      "Progress: 1600/7518 days | 46,576 rows scraped\n",
      "Progress: 1600/7518 days | 46,576 rows scraped\n",
      "Progress: 1700/7518 days | 49,369 rows scraped\n",
      "Progress: 1700/7518 days | 49,369 rows scraped\n",
      "Progress: 1800/7518 days | 52,012 rows scraped\n",
      "Progress: 1800/7518 days | 52,012 rows scraped\n",
      "Progress: 1900/7518 days | 54,931 rows scraped\n",
      "Progress: 1900/7518 days | 54,931 rows scraped\n",
      "Progress: 2000/7518 days | 57,757 rows scraped\n",
      "Progress: 2000/7518 days | 57,757 rows scraped\n",
      "Progress: 2100/7518 days | 60,482 rows scraped\n",
      "Progress: 2100/7518 days | 60,482 rows scraped\n",
      "Progress: 2200/7518 days | 63,254 rows scraped\n",
      "Progress: 2200/7518 days | 63,254 rows scraped\n",
      "Progress: 2300/7518 days | 66,248 rows scraped\n",
      "Progress: 2300/7518 days | 66,248 rows scraped\n",
      "Progress: 2400/7518 days | 69,170 rows scraped\n",
      "Progress: 2400/7518 days | 69,170 rows scraped\n",
      "Progress: 2500/7518 days | 71,786 rows scraped\n",
      "Progress: 2500/7518 days | 71,786 rows scraped\n",
      "Progress: 2600/7518 days | 74,562 rows scraped\n",
      "Progress: 2600/7518 days | 74,562 rows scraped\n",
      "Progress: 2700/7518 days | 77,430 rows scraped\n",
      "Progress: 2700/7518 days | 77,430 rows scraped\n",
      "Progress: 2800/7518 days | 80,167 rows scraped\n",
      "Progress: 2800/7518 days | 80,167 rows scraped\n",
      "Progress: 2900/7518 days | 82,799 rows scraped\n",
      "Progress: 2900/7518 days | 82,799 rows scraped\n",
      "Progress: 3000/7518 days | 85,701 rows scraped\n",
      "Progress: 3000/7518 days | 85,701 rows scraped\n",
      "Progress: 3100/7518 days | 88,675 rows scraped\n",
      "Progress: 3100/7518 days | 88,675 rows scraped\n",
      "Progress: 3200/7518 days | 91,351 rows scraped\n",
      "Progress: 3200/7518 days | 91,351 rows scraped\n",
      "Progress: 3300/7518 days | 93,724 rows scraped\n",
      "Progress: 3300/7518 days | 93,724 rows scraped\n",
      "Progress: 3400/7518 days | 96,135 rows scraped\n",
      "Progress: 3400/7518 days | 96,135 rows scraped\n",
      "Progress: 3500/7518 days | 98,547 rows scraped\n",
      "Progress: 3500/7518 days | 98,547 rows scraped\n",
      "Progress: 3600/7518 days | 101,241 rows scraped\n",
      "Progress: 3600/7518 days | 101,241 rows scraped\n",
      "Progress: 3700/7518 days | 104,094 rows scraped\n",
      "Progress: 3700/7518 days | 104,094 rows scraped\n",
      "Progress: 3800/7518 days | 107,043 rows scraped\n",
      "Progress: 3800/7518 days | 107,043 rows scraped\n",
      "Progress: 3900/7518 days | 109,909 rows scraped\n",
      "Progress: 3900/7518 days | 109,909 rows scraped\n",
      "Progress: 4000/7518 days | 112,590 rows scraped\n",
      "Progress: 4000/7518 days | 112,590 rows scraped\n",
      "Progress: 4100/7518 days | 115,660 rows scraped\n",
      "Progress: 4100/7518 days | 115,660 rows scraped\n",
      "Progress: 4200/7518 days | 118,920 rows scraped\n",
      "Progress: 4200/7518 days | 118,920 rows scraped\n",
      "Progress: 4300/7518 days | 121,875 rows scraped\n",
      "Progress: 4300/7518 days | 121,875 rows scraped\n",
      "Progress: 4400/7518 days | 124,675 rows scraped\n",
      "Progress: 4400/7518 days | 124,675 rows scraped\n",
      "Progress: 4500/7518 days | 127,816 rows scraped\n",
      "Progress: 4500/7518 days | 127,816 rows scraped\n",
      "Progress: 4600/7518 days | 130,492 rows scraped\n",
      "Progress: 4600/7518 days | 130,492 rows scraped\n",
      "Progress: 4700/7518 days | 133,035 rows scraped\n",
      "Progress: 4700/7518 days | 133,035 rows scraped\n",
      "Progress: 4800/7518 days | 135,972 rows scraped\n",
      "Progress: 4800/7518 days | 135,972 rows scraped\n",
      "Progress: 4900/7518 days | 138,949 rows scraped\n",
      "Progress: 4900/7518 days | 138,949 rows scraped\n",
      "Progress: 5000/7518 days | 141,702 rows scraped\n",
      "Progress: 5000/7518 days | 141,702 rows scraped\n",
      "Progress: 5100/7518 days | 144,549 rows scraped\n",
      "Progress: 5100/7518 days | 144,549 rows scraped\n",
      "Progress: 5200/7518 days | 147,544 rows scraped\n",
      "Progress: 5200/7518 days | 147,544 rows scraped\n",
      "Progress: 5300/7518 days | 150,545 rows scraped\n",
      "Progress: 5300/7518 days | 150,545 rows scraped\n",
      "Progress: 5400/7518 days | 153,257 rows scraped\n",
      "Progress: 5400/7518 days | 153,257 rows scraped\n",
      "Progress: 5500/7518 days | 156,072 rows scraped\n",
      "Progress: 5500/7518 days | 156,072 rows scraped\n",
      "Progress: 5600/7518 days | 159,225 rows scraped\n",
      "Progress: 5600/7518 days | 159,225 rows scraped\n",
      "Progress: 5700/7518 days | 162,050 rows scraped\n",
      "Progress: 5700/7518 days | 162,050 rows scraped\n",
      "Progress: 5800/7518 days | 164,679 rows scraped\n",
      "Progress: 5800/7518 days | 164,679 rows scraped\n",
      "Progress: 5900/7518 days | 167,751 rows scraped\n",
      "Progress: 5900/7518 days | 167,751 rows scraped\n",
      "Progress: 6000/7518 days | 170,875 rows scraped\n",
      "Progress: 6000/7518 days | 170,875 rows scraped\n",
      "Progress: 6100/7518 days | 173,410 rows scraped\n",
      "Progress: 6100/7518 days | 173,410 rows scraped\n",
      "Progress: 6200/7518 days | 176,407 rows scraped\n",
      "Progress: 6200/7518 days | 176,407 rows scraped\n",
      "Progress: 6300/7518 days | 179,831 rows scraped\n",
      "Progress: 6300/7518 days | 179,831 rows scraped\n",
      "Progress: 6400/7518 days | 182,814 rows scraped\n",
      "Progress: 6400/7518 days | 182,814 rows scraped\n",
      "Progress: 6500/7518 days | 185,621 rows scraped\n",
      "Progress: 6500/7518 days | 185,621 rows scraped\n",
      "Progress: 6600/7518 days | 188,599 rows scraped\n",
      "Progress: 6600/7518 days | 188,599 rows scraped\n",
      "Progress: 6700/7518 days | 191,781 rows scraped\n",
      "Progress: 6700/7518 days | 191,781 rows scraped\n",
      "Progress: 6800/7518 days | 194,575 rows scraped\n",
      "Progress: 6800/7518 days | 194,575 rows scraped\n",
      "Progress: 6900/7518 days | 197,278 rows scraped\n",
      "Progress: 6900/7518 days | 197,278 rows scraped\n",
      "Progress: 7000/7518 days | 200,548 rows scraped\n",
      "Progress: 7000/7518 days | 200,548 rows scraped\n",
      "Progress: 7100/7518 days | 203,788 rows scraped\n",
      "Progress: 7100/7518 days | 203,788 rows scraped\n",
      "Progress: 7200/7518 days | 206,513 rows scraped\n",
      "Progress: 7200/7518 days | 206,513 rows scraped\n",
      "Progress: 7300/7518 days | 209,545 rows scraped\n",
      "Progress: 7300/7518 days | 209,545 rows scraped\n",
      "Progress: 7400/7518 days | 212,925 rows scraped\n",
      "Progress: 7400/7518 days | 212,925 rows scraped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/6gm9txkn3c5dpfy0ct5gm25m0000gp/T/ipykernel_7835/3870681857.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scraped 7489/7518 days for KSEA | Total rows: 215,893\n",
      "Running total: 824,465 rows across 4 stations\n",
      "\n",
      "==================================================\n",
      "✓ Scraping complete!\n",
      "==================================================\n",
      "\n",
      "Total rows scraped: 824,465\n",
      "\n",
      "First 5 rows:\n",
      "  obs_id  valid_time_gmt      wx_phrase  temp  precip_hrly  snow_hrly  wspd  \\\n",
      "0   KPHL       560059200  Partly Cloudy  58.0          NaN        NaN   7.0   \n",
      "1   KPHL       560062800  Partly Cloudy  55.0          NaN        NaN   9.0   \n",
      "2   KPHL       560066400           Fair  57.0          NaN        NaN  10.0   \n",
      "3   KPHL       560070000           Fair  57.0          NaN        NaN  10.0   \n",
      "4   KPHL       560073600  Partly Cloudy  55.0          NaN        NaN  13.0   \n",
      "\n",
      "  clds    rh   vis  \n",
      "0  SCT  78.0  10.0  \n",
      "1  SCT  86.0  10.0  \n",
      "2  CLR  81.0  15.0  \n",
      "3  CLR  74.0  15.0  \n",
      "4  SCT  74.0  15.0  \n",
      "\n",
      "==================================================\n",
      "✓ Scraping complete!\n",
      "==================================================\n",
      "\n",
      "Total rows scraped: 824,465\n",
      "\n",
      "First 5 rows:\n",
      "  obs_id  valid_time_gmt      wx_phrase  temp  precip_hrly  snow_hrly  wspd  \\\n",
      "0   KPHL       560059200  Partly Cloudy  58.0          NaN        NaN   7.0   \n",
      "1   KPHL       560062800  Partly Cloudy  55.0          NaN        NaN   9.0   \n",
      "2   KPHL       560066400           Fair  57.0          NaN        NaN  10.0   \n",
      "3   KPHL       560070000           Fair  57.0          NaN        NaN  10.0   \n",
      "4   KPHL       560073600  Partly Cloudy  55.0          NaN        NaN  13.0   \n",
      "\n",
      "  clds    rh   vis  \n",
      "0  SCT  78.0  10.0  \n",
      "1  SCT  86.0  10.0  \n",
      "2  CLR  81.0  15.0  \n",
      "3  CLR  74.0  15.0  \n",
      "4  SCT  74.0  15.0  \n",
      "\n",
      "✓ Data saved to: weather_data_list5.csv\n",
      "\n",
      "✓ Data saved to: weather_data_list5.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Scrape weather for all ICAO codes (list 5) - OPTIMIZED ASYNC VERSION ---\n",
    "print(\"Starting async scraping for list 5...\")\n",
    "print(f\"Stations to scrape: {list5}\")\n",
    "\n",
    "# Run the async scraping\n",
    "all_weather_5 = await scrape_all_stations_async(list5, '1987-10-01', '2008-04-30')\n",
    "\n",
    "# Combine all stations into one DataFrame\n",
    "if all_weather_5:\n",
    "    df_all_weather_5 = pd.concat(all_weather_5, ignore_index=True)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ Scraping complete!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nTotal rows scraped: {len(df_all_weather_5):,}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_all_weather_5.head())\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = 'weather_data_list5.csv'\n",
    "    df_all_weather_5.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n✗ No data was scraped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
